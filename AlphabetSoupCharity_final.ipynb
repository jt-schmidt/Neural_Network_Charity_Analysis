{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deliverable 1: Preprocessing the Data for a Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EIN</th>\n",
       "      <th>NAME</th>\n",
       "      <th>APPLICATION_TYPE</th>\n",
       "      <th>AFFILIATION</th>\n",
       "      <th>CLASSIFICATION</th>\n",
       "      <th>USE_CASE</th>\n",
       "      <th>ORGANIZATION</th>\n",
       "      <th>STATUS</th>\n",
       "      <th>INCOME_AMT</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS</th>\n",
       "      <th>ASK_AMT</th>\n",
       "      <th>IS_SUCCESSFUL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10520599</td>\n",
       "      <td>BLUE KNIGHTS MOTORCYCLE CLUB</td>\n",
       "      <td>T10</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10531628</td>\n",
       "      <td>AMERICAN CHESAPEAKE CLUB CHARITABLE TR</td>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Co-operative</td>\n",
       "      <td>1</td>\n",
       "      <td>1-9999</td>\n",
       "      <td>N</td>\n",
       "      <td>108590</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10547893</td>\n",
       "      <td>ST CLOUD PROFESSIONAL FIREFIGHTERS</td>\n",
       "      <td>T5</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C3000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10553066</td>\n",
       "      <td>SOUTHSIDE ATHLETIC ASSOCIATION</td>\n",
       "      <td>T3</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>10000-24999</td>\n",
       "      <td>N</td>\n",
       "      <td>6692</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10556103</td>\n",
       "      <td>GENETIC RESEARCH INSTITUTE OF THE DESERT</td>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>Heathcare</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>100000-499999</td>\n",
       "      <td>N</td>\n",
       "      <td>142590</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        EIN                                      NAME APPLICATION_TYPE  \\\n",
       "0  10520599              BLUE KNIGHTS MOTORCYCLE CLUB              T10   \n",
       "1  10531628    AMERICAN CHESAPEAKE CLUB CHARITABLE TR               T3   \n",
       "2  10547893        ST CLOUD PROFESSIONAL FIREFIGHTERS               T5   \n",
       "3  10553066            SOUTHSIDE ATHLETIC ASSOCIATION               T3   \n",
       "4  10556103  GENETIC RESEARCH INSTITUTE OF THE DESERT               T3   \n",
       "\n",
       "        AFFILIATION CLASSIFICATION      USE_CASE  ORGANIZATION  STATUS  \\\n",
       "0       Independent          C1000    ProductDev   Association       1   \n",
       "1       Independent          C2000  Preservation  Co-operative       1   \n",
       "2  CompanySponsored          C3000    ProductDev   Association       1   \n",
       "3  CompanySponsored          C2000  Preservation         Trust       1   \n",
       "4       Independent          C1000     Heathcare         Trust       1   \n",
       "\n",
       "      INCOME_AMT SPECIAL_CONSIDERATIONS  ASK_AMT  IS_SUCCESSFUL  \n",
       "0              0                      N     5000              1  \n",
       "1         1-9999                      N   108590              1  \n",
       "2              0                      N     5000              0  \n",
       "3    10000-24999                      N     6692              1  \n",
       "4  100000-499999                      N   142590              1  "
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Deliverable 1.1\n",
    "\n",
    "# Import our dependencies\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler,OneHotEncoder\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "#  Import and read the charity_data.csv.\n",
    "import pandas as pd \n",
    "application_df = pd.read_csv(\"charity_data.csv\")\n",
    "application_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deliverable 1.1\n",
    "What variable(s) are considered the target(s) for the model?\n",
    "What variable(s) are considered the feature(s) for the model?\n",
    "\n",
    "From:\n",
    "https://medium.com/technology-nineleaps/some-key-machine-learning-definitions-b524eb6cb48#:~:text=Target%3A%20The%20target%20is%20whatever,range%20in%20a%20regression%20problem.\n",
    "\"Target: The target is whatever the output of the input variables. It could be the individual classes that the input variables maybe mapped to in case of a classification problem or the output value range in a regression problem. If the training set is considered then the target is the training output values that will be considered.\"\n",
    "\n",
    "\"Feature: Features are individual independent variables that act as the input in your system. Prediction models use features to make predictions. New features can also be obtained from old features using a method known as ‘feature engineering’. More simply, you can consider one column of your data set to be one feature. Sometimes these are also called attributes. And the number of features are called dimensions.\"\n",
    "\n",
    "Features would be columns with larger number of unique values (>10).\n",
    "Targets would be categorical columns with \"rare\" variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>APPLICATION_TYPE</th>\n",
       "      <th>AFFILIATION</th>\n",
       "      <th>CLASSIFICATION</th>\n",
       "      <th>USE_CASE</th>\n",
       "      <th>ORGANIZATION</th>\n",
       "      <th>STATUS</th>\n",
       "      <th>INCOME_AMT</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS</th>\n",
       "      <th>ASK_AMT</th>\n",
       "      <th>IS_SUCCESSFUL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T10</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Co-operative</td>\n",
       "      <td>1</td>\n",
       "      <td>1-9999</td>\n",
       "      <td>N</td>\n",
       "      <td>108590</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>T5</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C3000</td>\n",
       "      <td>ProductDev</td>\n",
       "      <td>Association</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>T3</td>\n",
       "      <td>CompanySponsored</td>\n",
       "      <td>C2000</td>\n",
       "      <td>Preservation</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>10000-24999</td>\n",
       "      <td>N</td>\n",
       "      <td>6692</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>T3</td>\n",
       "      <td>Independent</td>\n",
       "      <td>C1000</td>\n",
       "      <td>Heathcare</td>\n",
       "      <td>Trust</td>\n",
       "      <td>1</td>\n",
       "      <td>100000-499999</td>\n",
       "      <td>N</td>\n",
       "      <td>142590</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  APPLICATION_TYPE       AFFILIATION CLASSIFICATION      USE_CASE  \\\n",
       "0              T10       Independent          C1000    ProductDev   \n",
       "1               T3       Independent          C2000  Preservation   \n",
       "2               T5  CompanySponsored          C3000    ProductDev   \n",
       "3               T3  CompanySponsored          C2000  Preservation   \n",
       "4               T3       Independent          C1000     Heathcare   \n",
       "\n",
       "   ORGANIZATION  STATUS     INCOME_AMT SPECIAL_CONSIDERATIONS  ASK_AMT  \\\n",
       "0   Association       1              0                      N     5000   \n",
       "1  Co-operative       1         1-9999                      N   108590   \n",
       "2   Association       1              0                      N     5000   \n",
       "3         Trust       1    10000-24999                      N     6692   \n",
       "4         Trust       1  100000-499999                      N   142590   \n",
       "\n",
       "   IS_SUCCESSFUL  \n",
       "0              1  \n",
       "1              1  \n",
       "2              0  \n",
       "3              1  \n",
       "4              1  "
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Deliverable 1.2\n",
    "# Drop the non-beneficial ID columns, 'EIN' and 'NAME'.\n",
    "app_modify_df = application_df.drop(['EIN','NAME'], axis=1)\n",
    "app_modify_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No.of.unique values in each column:\n",
      " APPLICATION_TYPE            17\n",
      "AFFILIATION                  6\n",
      "CLASSIFICATION              71\n",
      "USE_CASE                     5\n",
      "ORGANIZATION                 4\n",
      "STATUS                       2\n",
      "INCOME_AMT                   9\n",
      "SPECIAL_CONSIDERATIONS       2\n",
      "ASK_AMT                   8747\n",
      "IS_SUCCESSFUL                2\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Deliverable 1.3\n",
    "# Determine the number of unique values in each column.\n",
    "# check the values of  \n",
    "# each row for each column \n",
    "n = app_modify_df.nunique(axis=0) \n",
    "  \n",
    "print(\"No.of.unique values in each column:\\n\",n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Columns with >10 Unique Values:\n",
    "\n",
    "APPLICATION_TYPE            17\n",
    "\n",
    "CLASSIFICATION              71\n",
    "\n",
    "ASK_AMT                   8747"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T3     27037\n",
      "T4      1542\n",
      "T6      1216\n",
      "T5      1173\n",
      "T19     1065\n",
      "T8       737\n",
      "T7       725\n",
      "T10      528\n",
      "T9       156\n",
      "T13       66\n",
      "T12       27\n",
      "T2        16\n",
      "T25        3\n",
      "T14        3\n",
      "T15        2\n",
      "T29        2\n",
      "T17        1\n",
      "Name: APPLICATION_TYPE, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Deliverable 1.4\n",
    "# Look at APPLICATION_TYPE value counts for binning\n",
    "APP_TYPE = app_modify_df.APPLICATION_TYPE.value_counts()\n",
    "print(APP_TYPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x213093c6108>"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZsAAAD4CAYAAAA6j0u4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO3deXxd1ZXg+9+692qercEabQtPsmxsBmFCICmDSTAQcNJFKqY6VXQ3Xel+gUrlUa86kMpLp6miukhehXr5PJIKnVQ3SVcChFDBEAMZmBJG2xjPki3PsiRb8zzf9f64R0YWV9ZgnXvusL4f7odz99ln37VlSUtnn332EVXFGGOMcZPP6wCMMcbEP0s2xhhjXGfJxhhjjOss2RhjjHGdJRtjjDGuC3gdQDQqKCjQJUuWeB2GMcbElJ07d7aqamG4fZZswliyZAk7duzwOgxjjIkpInJiqn02jGaMMcZ1lmyMMca4zpKNMcYY11myMcYY4zpLNsYYY1xnycYYY4zrLNkYY4xxnd1nYzx3oq2Pl/Y3kxLwc/OaYoqyU70OyRgzz1w9sxGRTSJSJyL1InJ/mP0pIvKks/8dEVkyYd8DTnmdiNw0XZsicq9TpiJSMKFcROQ7zr49InKFez02s/WD3x3lhn94jb/bVst/3bqfjf/wGr/a3+x1WMaYeeZashERP/AocDNQDdwpItWTqt0NdKjqMuAR4GHn2GpgC7Aa2AR8V0T807T5BnAjMPkO1puB5c7rC8D35rOfZu5+/PYJ/vaXB/nEqoW89cAN/Oa+P+CSwgzu+cl7vHWkzevwjDHzyM0zm/VAvaoeVdVh4Alg86Q6m4HHne2ngY0iIk75E6o6pKrHgHqnvSnbVNVdqno8TBybgR9pyNtAroiUzGtPzawdOtPD3zx3gA0rC3n0315BSU4ay4oy+dHdV7NoQTpffnIX3YMjXodpjJknbiabMuDUhPcNTlnYOqo6CnQB+Rc4diZtziUOROQLIrJDRHa0tLRM06S5GKrKN7buJy3Zz7f/6DL8Pjm3LyctiW//0WW09Azx7V8d8jBKY8x8cjPZSJgynWGd2ZZfbByo6mOqWqOqNYWFYRctNfPkjfo23jzSxn2fWMGCjOQP7V9XkcvnrqrgJ++c5HTngAcRGmPmm5vJpgGomPC+HGicqo6IBIAcoP0Cx86kzbnEYSLo+68foTArhS3rK6asc+8Ny1GU//H60QhGZoxxi5vJZjuwXEQqRSSZ0AX/rZPqbAXucrbvAF5WVXXKtziz1SoJXdx/d4ZtTrYV+FNnVtpHgC5VbZqPDprZ29/Yxe8Ot/Ifrq0kJeCfsl5Zbhq3XlrCz3c20Dc0GsEIjTFucC3ZONdg7gVeAg4CT6nqfhF5UERud6r9EMgXkXrgPuB+59j9wFPAAeBF4B5VHZuqTQAR+ZKINBA6c9kjIj9wPmMbcJTQJIP/AXzRrT6b6f303ZOkBHz88dWLpq37J9csoWdolH/ddToCkRlj3CShEwkzUU1NjdrD0+bf4MgY6x/6DTdUFfGPWy6ftr6qcut3fo/PB8//+cciEKEx5mKIyE5VrQm3z5arMRHz6wNn6B4c5Y4rp75WM5GI8G+uKGPf6W6OtvS6HJ0xxk2WbEzEPLe7keLsVD66NH/Gx3xqbSkisHW3zekwJpZZsjERMTA8xuuHW7hp9UJ8vnCz0cMrzkll/ZIFbN3diA35GhO7LNmYiHj9cAuDI0E+ubp41sfeuraEoy19HG3tcyEyY0wkWLIxEfHS/mZy0pJYX7lg1sfeUFUEwCu1Z+c7LGNMhFiyMa4bHQvycu1ZNlYVkeSf/bdceV46Kxdm8duDlmyMiVWWbIzrdjd00dk/wsZVC+fcxvVVRWw/3m6LcxoToyzZGNe9Ud+KCLOahTbZxlVFjAaV3x1qncfIjDGRYsnGuO739a2sKc0hL8yimzN1eUUuWakBfl9vK3IbE4ss2RhX9Q+PsutkB9cuK5i+8gUE/D6ursznTXuomjExyZKNcdW7x9oZGVOuu8hkA6FhuBNt/fbYAWNikCUb46o36ltJDvioWZJ30W1d41zzsUdGGxN7LNkYV/2+vo2axXmkJk39OIGZWrkwi7z0JEs2xsQgSzbGNV0DI9Q2d/ORS+Y+C20in0+4Zmk+bx1ptaVrjIkxlmyMa9472YEq8zKENu7qynwauwZp7BqctzaNMe6zZGNcs/N4B36fcFlF7ry1eeXiUOLaeaJj3to0xrjPko1xzY4T7VSXZJOeHJi3NquKs0hP9vOeJRtjYoolG+OKkbEg75/qPHcmMl8Cfh+XVeTamY0xMcaSjXHF/sZuBkeC83q9ZtyVi/M40NRN//DovLdtjHGHJRvjih3H2wGoWTz7RwpM54rFeYwFlfdPdc5728YYd1iyMa5472QHZblpFOekznvbV1SEzpbsuo0xscOSjXHF+yc7uXzR/M1CmygnPYnlRZnssGRjTMywZGPmXUvPEI1dg6wrdyfZAFy+KJfdpzrt5k5jYoQlGzPv9p3uAuDS8hzXPmNteS4d/SM0dNiinMbEAks2Zt7tbuhEBNaUuZlsQm3vdRKbMSa6WbIx825vQxdLCzPJTJm/mzknW1mcRbLfx54GSzbGxAJLNmZeqSq7G7rOnXm4JSXgp6okiz0NNv3ZmFhgycbMq+buQVp7h1jr4hDauEvLcth7uotg0CYJGBPtLNmYebX7VGhYa+08Lr45lbXlOfQMjnKivd/1zzLGXBxLNmZe7T3dScAnVJdku/5Zl5aFEpoNpRkT/VxNNiKySUTqRKReRO4Psz9FRJ509r8jIksm7HvAKa8TkZuma1NEKp02DjttJjvli0TkFRHZJSJ7ROQWN/uc6PY0dLFiYda8PJlzOssXZpISsEkCxsQC15KNiPiBR4GbgWrgThGpnlTtbqBDVZcBjwAPO8dWA1uA1cAm4Lsi4p+mzYeBR1R1OdDhtA3wNeApVb3cafO7bvTXhCYH7InA5IBxSX4fq0uz2WvJxpio5+aZzXqgXlWPquow8ASweVKdzcDjzvbTwEYREaf8CVUdUtVjQL3TXtg2nWNucNrAafPTzrYC42M6OUDjPPfTOE61D9A1MOLqzZyTrS3PZV9jF2M2ScCYqOZmsikDTk143+CUha2jqqNAF5B/gWOnKs8HOp02Jn/WN4DPi0gDsA3483DBisgXRGSHiOxoaWmZeS/NOQeaugFYXRq5ZFNdmk3/8Bgn2voi9pnGmNlzM9lImLLJf35OVWe+ygHuBP6XqpYDtwA/FpEP9VtVH1PVGlWtKSwsDNOcmU5tczcisGJhZsQ+c3wiwsGmnoh9pjFm9txMNg1AxYT35Xx4COtcHREJEBrmar/AsVOVtwK5ThuTP+tu4CkAVX0LSAUKLqJfZgq1TT0syc+Y18dAT2f5wkwCPuFAk123MSaauZlstgPLnVliyYQuzm+dVGcrcJezfQfwsoaW8d0KbHFmq1UCy4F3p2rTOeYVpw2cNp91tk8CGwFEZBWhZGPjZC6oO9PDyoVZEf3MlICfZUWZHGjsjujnGmNmx7Vk41w/uRd4CThIaEbYfhF5UERud6r9EMgXkXrgPuB+59j9hM5GDgAvAveo6thUbTptfQW4z2kr32kb4C+BPxOR3cBPgX+nti79vOsfHuV4Wx9VJZFNNhAaShu/XmSMiU6ujneo6jZCF+Unln19wvYg8Nkpjn0IeGgmbTrlRwnNVptcfgC4draxm9k5dKYXVagqdv9mzsmqS7N5Ztdp2nqHyM9MifjnG2OmZysImHlR65xZrPLozAZskoAx0cySjZkXtc09pCf7qchLj/hnr3KSjU0SMCZ6WbIx86K2uZsVC7Pw+cLNQndXXkYypTmpNknAmChmycZcNFWltrnHkyG0cdWlNknAmGhmycZctLM9Q3T2j3gyOWDcqpJsjrT0MTgy5lkMxpipWbIxF+2gc0axstjDM5uSbMaCyqEzNknAmGhkycZctNrm0C/4Ki+TTen4jDQbSjMmGlmyMRettqmbkpxUctOTPYuhIi+dzJSATRIwJkpZsjEXrba5x9MhNACfT6gqzrJ7bYyJUpZszEUZHg1ypKXX08kB41YWZ1Hb3I2tRmRM9LFkYy7K0dZeRsbU02nP46qKs+geHKW5e9DrUIwxk1iyMReltml8ckA0nNmEYhifsGCMiR6WbMxFqW3uIckvXFKY4XUo5x5vUGvXbYyJOpZszEWpbe5maWEmSX7vv5Vy0pMoyUmlrtlmpBkTbbz/DWFiWm1Tz7mFMKNBaJKAndkYE20s2Zg56+wfprl70NObOSdbWZzFkZZeRsaCXodijJnAko2Zs/EzCK/vsZmoqjiLkTHlWGuf16EYYyawZGPm7IMHpkXRMNpCm5FmTDSyZGPmrLa5h7z0JIqyoudRzEuLMvD7xCYJGBNlLNmYOatt7qGqOBuRyD8wbSopAT+XFGRQZ2c2xkQVSzZmToJBpS4K1kQLx2akGRN9LNmYOTnZ3s/AyFhULFMzWVVxFg0dA/QOjXodijHGYcnGzMkHz7CJnskB48aXrbGhNGOihyUbMye1zd2IwIqF0XlmA5ZsjIkmlmzMnNQ29bAkP4O0ZL/XoXxIWW4aGcl+m5FmTBSxZGPmpLa5O6pWDpjI5xNW2CQBY6KKJRsza/3Do5xo74/K6zXjqoqzqTvTYw9SMyZKWLIxs3boTC+q0bVMzWRVxVl09o9wtmfI61CMMViyMXPwwTI10ZtsxhOhDaUZEx0s2ZhZq23uIT3ZT0VeutehTOmDGWk2ScCYaOBqshGRTSJSJyL1InJ/mP0pIvKks/8dEVkyYd8DTnmdiNw0XZsiUum0cdhpM3nCvj8SkQMisl9EfuJejxNDbXM3K4uz8PmiZ5mayXLTk1mYnWJnNsZECdeSjYj4gUeBm4Fq4E4RqZ5U7W6gQ1WXAY8ADzvHVgNbgNXAJuC7IuKfps2HgUdUdTnQ4bSNiCwHHgCuVdXVwJdd6nJCUFVnTbToHUIbt7I42+61MSZKuHlmsx6oV9WjqjoMPAFsnlRnM/C4s/00sFFCqzpuBp5Q1SFVPQbUO+2FbdM55ganDZw2P+1s/xnwqKp2AKjqWRf6mjDOdA/R2T8S1TPRxlUVZ3H4bC+j9iA1YzznZrIpA05NeN/glIWto6qjQBeQf4FjpyrPBzqdNiZ/1gpghYi8ISJvi8imcMGKyBdEZIeI7GhpaZlVRxNJrXMNJCbObBZmMTwa5Hhbv9ehGJPw3Ew24Qb0J9/0MFWd+SoHCADLgQ3AncAPRCT3Q5VVH1PVGlWtKSwsDNOcgeheE22yD2ak2SQBY7w2o2QjIj8XkVtFZDbJqQGomPC+HGicqo6IBIAcoP0Cx05V3grkOm1M/qwG4FlVHXGG5OoIJR8zB7VN3ZTkpJKTnuR1KNNaVpTpPEjNrtsY47WZJo/vAX8MHBaRvxeRqhkcsx1Y7swSSyZ0wX/rpDpbgbuc7TuAlzV0y/dWYIszW62SUHJ4d6o2nWNecdrAafNZZ/sXwPUAIlJAaFjt6Az7bSaJlckBAKlJfioLMjjYZMnGGK/NKNmo6m9U9d8CVwDHgV+LyJsi8u9FJOyfuM71k3uBl4CDwFOqul9EHhSR251qPwTyRaQeuA+43zl2P/AUcAB4EbhHVcematNp6yvAfU5b+U7bOHXbROQAoYT0V6raNpN+m/MNjwY50tJLVUn0D6GNqyrOou6MDaMZ47XA9FVCRCQf+DzwJ8Au4F+A6widRWwId4yqbgO2TSr7+oTtQeCzUxz7EPDQTNp0yo8Smq02uVwJJbL7wnbMzNjR1l5GxjRmzmwAVpVk8/yeJnoGR8hKjf6hP2Pi1Uyv2TwD/A5IB25T1dtV9UlV/XMg080ATfSobYqdyQHjxhPjoTM2lGaMl2Z6ZvMD54ziHBFJce6DqXEhLhOFapt7SPILlxRmeB3KjE1cI+3KxQs8jsaYxDXTCQJ/G6bsrfkMxES/2uZulhVlkeSPnSX1ynLTyEoJnDsrM8Z444JnNiJSTOjmyDQRuZwP7mfJJjSkZhJIbVMP1yzN9zqMWRERqkqy7F4bYzw23TDaTcC/I3TfyrcnlPcAX3UpJhOFOvuHae4ejKnJAeNWFmfx7PuNqCqhlY2MMZF2wWSjqo8Dj4vIH6rqzyMUk4lC51YOiKFpz+OqirP534MnaewapCw3zetwjElI0w2jfV5V/zewREQ+NHVYVb8d5jATh849MC0Gz2zGH/JW29RtycYYj0x3pXd82lEmkBXmZRJEbXMPeelJFGaleB3KrK1YaE/tNMZr0w2jfd/5/3+LTDgmWh1s6mZVSXZMXvPISk2iPC/Nko0xHprpTZ3fFJFsEUkSkd+KSKuIfN7t4Ex0GAsqdWd6YupmzsmqirPPDQUaYyJvpjdMfFJVu4FPEVpFeQXwV65FZaLK8bY+BkeC5659xKKq4iyOtvYxNDrmdSjGJKSZJpvxRaVuAX6qqu0uxWOi0PgNkaticCbauKqSLMaCSv3ZXq9DMSYhzTTZPCcitUAN8FsRKQQG3QvLRJODTd34fcKyothdBm98CNBWEjDGGzN9xMD9wDVAjaqOAH3AZjcDM9HjYFM3SwszSE3yex3KnC3JTyc54KPOFuQ0xhMzfsQAsIrQ/TYTj/nRPMdjolBoEcs8r8O4KAG/jxULMzlokwSM8cSMko2I/BhYCrwPjF9hVSzZxL2u/hFOdw7w+Y8s9jqUi1ZVnM1rh1q8DsOYhDTTM5saoNp5EJlJIAedBSxjeSbauKriLJ7e2UBb7xD5mbF3c6oxsWymEwT2AcVuBmKi07llamJ4Jtq48UkCdXZzpzERN9MzmwLggIi8CwyNF6rq7a5EZaLGwaYeFmQkUxSDy9RMVuWcnR1s7uGjywo8jsaYxDLTZPMNN4Mw0etgczerSrJicpmayQoyUyjITKHOnm1jTMTNdOrza8BxIMnZ3g6852JcJgqMBZW65thepmayquIsDtq9NsZE3EzXRvsz4Gng+05RGfALt4Iy0eFYax9Do8G4uF4zrro0m7ozPYyMBb0OxZiEMtMJAvcA1wLdAKp6GChyKygTHQ42xc9MtHGrS7MZHg1ypMWWrTEmkmaabIZUdXj8jXNjp02DjnO1zd0EYnyZmslWl4bO0vaftus2xkTSTJPNayLyVSBNRD4B/Ax4zr2wTDQ42NTD0sJMUgKxu0zNZJUFmaQl+dnX2OV1KMYklJkmm/uBFmAv8J+AbcDX3ArKRIfapu64GkID8PuEqpIs9jfamY0xkTSjqc+qGhSRXwC/UFVb7yMBtPcN09g1GFeTA8atLs3m2V2NBIOKzxf7U7qNiQUXPLORkG+ISCtQC9SJSIuIfD0y4Rmv7HeGmS4ty/E4kvm3pjSHnqFRTnX0ex2KMQljumG0LxOahXaVquar6gLgauBaEfk/XY/OeGbv6VCyWV0af8lmvE/7bJKAMREzXbL5U+BOVT02XqCqR4HPO/tMnNp/uptFC9LJSU+avnKMWVGcScAn587ejDHumy7ZJKlq6+RC57rNtL+FRGSTiNSJSL2I3B9mf4qIPOnsf0dElkzY94BTXiciN03XpohUOm0cdtpMnvRZd4iIikjNdHGb0JnNmrL4u14DkBLws6wo0yYJGBNB0yWb4TnuQ0T8wKPAzUA1cKeIVE+qdjfQoarLgEeAh51jq4EtwGpgE/BdEfFP0+bDwCOquhzocNoejyUL+BLwzjT9NYSeYXOyvT8uh9DGrS7NYX9jF/bUDGMiY7pks05EusO8eoBLpzl2PVCvqkedG0Kf4MOPkt4MPO5sPw1slNCKj5uBJ1R1yBnCq3faC9umc8wNThs4bX56wuf8DfBNYHCamA2wvyl+JweMW1OWTWvvMGd7hqavbIy5aBdMNqrqV9XsMK8sVZ1uGK0MODXhfYNTFraOqo4CXUD+BY6dqjwf6HTaOO+zRORyoEJVn79QsCLyBRHZISI7WloSe3b3vnOTA+JzGA0+mCRg122MiYyZ3tQ5F+FuYJg8ZjFVnXkpFxEfoeG5v7xAnKHKqo+pao2q1hQWFk5XPa7tO91NaU5qXD/NcvxmVVu2xpjIcDPZNAAVE96XA41T1XHWW8sB2i9w7FTlrUCu08bE8ixgDfCqiBwHPgJstUkCF7avsYs1cTyEBpCVmsSS/HRbtsaYCHEz2WwHljuzxJIJXfDfOqnOVuAuZ/sO4GUNXbHdCmxxZqtVAsuBd6dq0znmFacNnDafVdUuVS1Q1SWqugR4G7hdVXe41elY1zs0yrHWvrhPNgCry3LsXhtjIsS1ZONcP7kXeAk4CDylqvtF5EERGX+c9A+BfBGpB+4jtAYbqrofeAo4ALwI3KOqY1O16bT1FeA+p618p20zSwcau1Elbqc9T7S2LIfTnQO09dokAWPcNtPHQs+Jqm4jtGjnxLKvT9geBD47xbEPAQ/NpE2n/Cih2WoXimfDTOJOZOOTAxLhzGZdRS4Aexq6uL7KHs9kjJvcHEYzMWjf6S6KslIoykr1OhTXrSnLQQR2N3R6HYoxcc+SjTnP7oZO1pbH/1kNQGZKgOVFmew+ZcnGGLdZsjHndA2McKSlj8uc4aVEsK48l90NtpKAMW6zZGPO2eMMJ61LpGRTkUt73zANHQNeh2JMXLNkY855/2Qo2awtT5xkM34WZ9dtjHGXJRtzzvunOllamEFOWvw9VmAqK4uzSA747LqNMS6zZGMAUFXeP9XJZRV5XocSUUl+H6tLs9l9ylYSMMZNlmwMAA0dA7T1DXPZosQZQhu3rjyXvae7GB0Leh2KMXHLko0BYJczjHR5Ak0OGHdZRS4DI2PUt/R6HYoxccuSjQFCkwNSAj5WFmd5HUrEjc++e++EXbcxxi2WbAwA75/q4NKyHJL8ifctsSQ/nfyMZHacaPc6FGPiVuL9ZjEfMjwaZF9jd0LdzDmRiHDl4jx2nujwOhRj4pYlG8OBpm6GR4NcviixZqJNdNWSBZxo6+dsjz053Bg3WLIxbD8WGj66akniJpsrnb7vPG5nN8a4wZKNYfvxdhbnp1OUHf8rPU9lTWkOKQEfO2wozRhXWLJJcKrKjhMd1Cxe4HUonkoO+FhXkWvJxhiXWLJJcEdaemnvG2Z9ZeIOoY2rWZzH/tNdDAyPeR2KMXHHkk2C2+5co7hqSWKf2QDULMljNBhatscYM78s2SS47cfaKchMprIgw+tQPHflolDC3XHc7rcxZr5Zsklw7x5vp2bxAkTE61A8l5OexIqFmWy36zbGzDtLNgmsqWuAho4Brqq0IbRxV1fms+N4OyO2KKcx88qSTQJ752houGi9Xa8559pl+fQPj517aqkxZn5Ysklgb9S3kpOWRHVpttehRI2rK/MRgTfq27wOxZi4YskmQakqb9S38tGl+fh9dr1mXF5GMtUl2bx5pNXrUIyJK5ZsEtTxtn4auwb56LICr0OJOh9dms97JzoZHLH7bYyZL5ZsEtTv60N/uV9nyeZDPrqsgOGxIDtsnTRj5o0lmwT1Zn0rZblpLMlP9zqUqHPVkgUEfGJDacbMI0s2CWgsqLx5pI2PLs23+2vCyEwJsK4ilzeO2CQBY+aLJZsEdKCxm66BEa5bbkNoU7luWQF7Gzrp6Bv2OhRj4oIlmwT0+uEWAK5Zmu9xJNHr+qoiggqvHWrxOhRj4oKryUZENolInYjUi8j9YfaniMiTzv53RGTJhH0POOV1InLTdG2KSKXTxmGnzWSn/D4ROSAie0TktyKy2M0+x4KXa89yaVkORVmJ+/ya6awty6EgM5mXa896HYoxccG1ZCMifuBR4GagGrhTRKonVbsb6FDVZcAjwMPOsdXAFmA1sAn4roj4p2nzYeARVV0OdDhtA+wCalR1LfA08E03+hsr2vuG2XWyg+urirwOJar5fMIfrCjitUMtjNrSNcZcNDfPbNYD9ap6VFWHgSeAzZPqbAYed7afBjZK6Ir1ZuAJVR1S1WNAvdNe2DadY25w2sBp89MAqvqKqvY75W8D5S70NWa8dugsQYWNlmymdX1VIV0DI/bIAWPmgZvJpgw4NeF9g1MWto6qjgJdQP4Fjp2qPB/odNqY6rMgdLbzQrhgReQLIrJDRHa0tMTvOP3LtS0UZKZwaVmO16FEvY8tL8TvExtKM2YeuJlsws2p1RnWma/yDz5I5PNADfCtMHVR1cdUtUZVawoLC8NViXmjY0FeqzvLhpWF+GyJmmnlpCVRszjPko0x88DNZNMAVEx4Xw40TlVHRAJADtB+gWOnKm8Fcp02PvRZInIj8NfA7ao6dFG9imHbj3fQPTjKDTaENmMbVxVR29zDqfb+6SsbY6bkZrLZDix3ZoklE7rgv3VSna3AXc72HcDLqqpO+RZntlolsBx4d6o2nWNecdrAafNZABG5HPg+oUST0H+ivrCviZSAjz9YEZ9nbm7YtLoEgBf3NXsciTGxzbVk41w/uRd4CTgIPKWq+0XkQRG53an2QyBfROqB+4D7nWP3A08BB4AXgXtUdWyqNp22vgLc57SV77QNoWGzTOBnIvK+iExOeAkhGFRe2NfM9SuLyEgJTH+AAWBRfjpryrLZtq/J61CMiWmu/tZR1W3AtkllX5+wPQh8dopjHwIemkmbTvlRQrPVJpffOOvA49COEx209Axx86XFXocSc25eU8K3XqqjsXOA0tw0r8MxJibZCgIJYtveJpIDPjauWuh1KDHnlktDQ2kv2FCaMXNmySYBBIPKi/ua2bCikEwbQpu1yoIMVpVks22vDaUZM1eWbBLA28faaO4e5Na1JV6HErNuW1fCzhMdnGjr8zoUY2KSJZsE8PTOBrJSAnyy2q7XzNVnLi9DBH7+3mmvQzEmJlmyiXO9Q6O8sLeZT60rIS3Z73U4MaskJ43rlhXwzHsNBIOT7002xkzHkk2ce2FvEwMjY9xxZUIvCTcv7riynIaOAd451u51KMbEHEs2ce7pnQ1UFmRwxaI8r0OJeZ+sLiYrJcDPdp6avrIx5jyWbOLYoTM9vHOsnTuuLLfHP8+DtGQ/my8v5fk9TbT1JuyqR8bMiSWbOPb4m8dJDvi4c/0ir0OJG3ddsz6KLwwAABEMSURBVITh0SBPbLezG2Nmw5JNnOrqH+GZ906zeV0pCzKSvQ4nbixfmMW1y/L5l7dP2EPVjJkFSzZx6mc7TzEwMsZdH13idShx50+vWUJj1yC/PnDG61CMiRmWbOLQ8GiQf/79MdYvWcAae0javLtx1UIWLUjne68dIbTguDFmOpZs4tDP32ugsWuQe25Y5nUoccnvE764YSl7Grp49VD8PtXVmPlkySbOjIwFefSVetZV5PLx5QVehxO3/s0V5ZTlpvGd3x62sxtjZsCSTZx55r0GGjoG+IuNy2y6s4uSAz7+84al7DrZyeuHW70Ox5ioZ8kmjvQNjfIPvzrEuopcrl9pj3522x/VlFOxII2/++VBm5lmzDQs2cSR7716hLM9Q3z9U9V2VhMBKQE/X715FXVnenhyh913Y8yFWLKJE6fa+3nsd0fZfFkpVy62pWkiZdOaYtZXLuAffnWIrv4Rr8MxJmpZsokDqspX/3UvAZ/wlU1VXoeTUESE/3pbNV0DIzz4/AGvwzEmatljG+PAT949ye8Ot/I3n15DaW6a1+EknNWlOdyzYSnfebmem9cUc2O1PXrbK31Do5zpHqStb5jh0SDDY0F8ImSmBMhKDbAwK5Wc9CSvw0xIlmxi3LHWPv7ulwe5blkBn7/a1kDzyr03LOdXB87wwL/uZW1FDkVZqV6HFNdUlSMtvbx7rIMDTV3UNfdQ19xD9+DotMdmpwZYlJ9OdUk2a8tzWVueQ3VJNgG/DfS4SewegQ+rqanRHTt2eB3GtHqHRvnMo2/Q2jvE81/6GGV2VuOp2uZuPvPom6wpy+Zf/uNHSA7YL6/51Dc0ym8OnuE3B8/y9tE2WnpCK29npQSoKsliZXEW5XnpLMxOIT8jhZSAj+SAj6AqPYOj9AyGznpOtvdzrLWPfae76HCus2WlBrh2aQEfX1HIhpWFNkIwRyKyU1Vrwu2zM5sYFQwq/9dTuznS0suP777aEk0UqCrO5uE71vKln+7iwef38zeb19iswIs0ODLGa4da2Lq7kd8ePMPgSJDCrBQ+ujSfay7J5yOX5LM4P31OX2dVpaFjgF2nOnmzvpXXD7Xw4v5mAC6ryOXWS0vYtKaYigXp892thGTJJgapKl97dh8v7m/ma7eu4tpltlJAtLh9XSn7G7v4/mtHWZCezH2fXOl1SDFndCzIm0fa2Lq7kZf2NdMzNEp+RjKfvbKC2y8r5cpFefh8F5/ERYSKBelULEjn9nWlztBcH7860My2vU08tO0gD207yLryHG5bV8qta0soybE/6ubKhtHCiOZhtGBQefD5A/yvN4/zxQ1L+S82+yzqqCr3/3wvT+44xV9+YgX33mCrOUwnGFR2nuxg6/uNbNvbRFvfMFkpAW5aU8xt60q5dml+xK+pnGzrZ9u+Jp7f08i+092IwFVLFnDbulJuWVNMfmZKROOJBRcaRrNkE0a0JpvBkTH+8qnd/HJvE3dfV8nXbl1lv8Si1FhQ+auf7eaZXaf546sX8eDtq+0C9CSqyv7GbrbubuT53Y00dg2SEvBx46qF3LaulA0rC0lN8nsdJgBHW3p5fk8TW3c3Un+2F79PuHZZAbetLeGmNcVkp9oMN7BkM2vRmGyOtvTy5SffZ09DF1+9pYo/+9gllmiiXDCofOtXdXzv1SOsr1zAI5+7LOGvrakqB5t62La3iV/ubeJYax8Bn/DxFYXcvq6UG6sXkpkSvaP7qkptcw/P7W5k6+5GGjoGSPb72LCykNsvK2Vj1ULSkqMjQXrBks0sRVOyGRkL8qO3TvD/vFRHSpKPb/7hWj65utjrsMwsPPNeA//3L/bh9wn337yKz11VgX8erjnEimBQOdDUzYv7QtdCjrb24RO4Zmk+n1pbys1rislNj72nyaoq75/qZOvuRn65p4mzPUOkJ/u5cdVCbl9XysdXFCbcjERLNrMUDclmdCzItn3NfOe3h6k/28sfrCjk4T9cS3GO3b8Ri0609fFXT+/h3WPtVJdk86WNy/lk9cJ5udAdjTr7h/nd4VZerWvhtUMttPYOnUswt1xawk2riymIo2seY0HlnWNtPLe7iRf2NdHZP0J2aoDrq4q4dlkB1y4rSIizWks2s+RlsjnR1sdzuxt5YvspGjoGuKQwg6/evIqNq4ps2CzGqSrP72niWy/VcbK9n0sKMvhsTQW3rSuhPC92p9eqKqfaB9hxop0dJzrYebyDQ2d7UIWctCQ+tryADSuL2LCyMK4SzFSGR4O8Ud/Kc7sbef1wC629wwBUFmTwkUsWsK48l7XluaxYmBl31/E8SzYisgn4fwE/8ANV/ftJ+1OAHwFXAm3A51T1uLPvAeBuYAz4kqq+dKE2RaQSeAJYALwH/ImqDl/oM6YSqWSjqrT2DrP7VCdvH23jraNt7G/sBmB95QL+43WV3Lgqfv/6TVSjY0Fe2NfM/3zjGO+d7ARgbXkO1ywN3TeyuiSbwqyUqPvjYng0SFPXAKfaBzjW2kttcw+1zT0cau6hZyh0535WSoDLF+dRsziPa5cVcFlFbkINGU6mqtSd6eGN+jbeqG9lx/H2c6scpCb5WF2aw/KiTJYWZrK0KINLCjIpzU2L2eE3T5KNiPiBQ8AngAZgO3Cnqh6YUOeLwFpV/c8isgX4jKp+TkSqgZ8C64FS4DfACuewsG2KyFPAM6r6hIj8E7BbVb831WdcKPaLSTaqysDIGH1DY/QNjdI7NEr/8Bgd/cOc7R7kbM8QZ7oHOd7Wz+EzPefuYE4O+Li8Ipcbqor41LrShDjlNqHptc/taeS1uhZ2nepgZCz085iXnsSKhVmU5aVRkpNKcU4ahZnJZKUmkZUacNb6SiI54CPJL/h9QpLPF/YPE1VlLKiMqaIaug44MDLG4HCQ/pFRBobHQq+RMXoGR2nrG6a9b4j2vmHa+4Zp6x3mdOcAzd2DTPx1kZUaoKo4dOf+qpJsrliUx4qFWQmdXKajqhxv62dPQyfvn+pk/+lujrT00tY3fF69gsxkinNSKc5Oozgnhdy0ZHLSkshJSyLb+X9WaoDUJB8pAT8pST5Sk/yhVRP8Ps/+UPEq2VwDfENVb3LePwCgqv99Qp2XnDpviUgAaAYKgfsn1h2v5xz2oTaBvwdagGJVHZ342VN9hl6g43NNNo+9foT//kItF/qS+n1CYWYKZXlprFiYyfKiLKpLs7msIjdqpnkab/QPj7L7VBe1zd3UNvVw+GwPzV2DnOkZYiw4s59TnxAamlEYUyXoJJjZ8vuEvPRkFmQksSAjmbLcdMrz0pxXOovz0ynJSY26s69Y1dE3zNHWXo6c7aOxa4Az3YM0dQ2G/v27B+kaGGGG3wKIQLLfh98n+EXw+QSfhP5NfRJ6+X2Cz0doWwRC/wHwFzeu4PZ1pXPqh1fL1ZQBE58o1QBcPVUdJ0l0AflO+duTji1ztsO1mQ90qupomPpTfcZ5z/IVkS8AXwBYtGhuC1peVpHHn1+/jPSUABnJfjJSAqQnB8hI8ZOTlkRxdir5mSn2l58JKz05wDVL87lmaf555WNBpbV3iNbeIXqdNb56h0bpGRpleDTI6FiQ0aAyMhZkdEwZCQYRBL8P/CKI88tl/JeN3wdpyQHSkvykJ/tJS/KTlhzazkgJkJ+RTHZqkg3fRlBeRjJXZizgysULwu4PBpXe4VG6+kfoGgi9+oZGGRwNMjQydu7/Q6NBBkfGGB4Nnnc2+8G2c5YbdM54nffn8phCbpo79wy5mWzCfadOzs1T1ZmqPNxA5oXqzzQOVPUx4DEIndmEOWZa6ysXsL4y/DeLMXPl9wkLs1NZmG0zEROVzydkpyaRnZpEhdfBzJGbV6Ea4LyvSznQOFUdZ4grB2i/wLFTlbcCuU4bkz9rqs8wxhgTIW4mm+3AchGpFJFkYAuwdVKdrcBdzvYdwMvOtZStwBYRSXFmmS0H3p2qTeeYV5w2cNp8dprPMMYYEyGuDaM510fuBV4iNE35n1V1v4g8COxQ1a3AD4Efi0g9obONLc6x+53ZZQeAUeAeVR0DCNem85FfAZ4Qkb8FdjltM9VnGGOMiRy7qTOMaFhBwBhjYs2FZqPF5p1DxhhjYoolG2OMMa6zZGOMMcZ1lmyMMca4ziYIhCEiLcAJr+NwFDBptYM4E+/9g/jvo/Uv9s1XHxeramG4HZZsopyI7Jhqdkc8iPf+Qfz30foX+yLRRxtGM8YY4zpLNsYYY1xnySb6PeZ1AC6L9/5B/PfR+hf7XO+jXbMxxhjjOjuzMcYY4zpLNsYYY1xnySbCROSzIrJfRIIiUjNp3wMiUi8idSJy04TyTU5ZvYjcP6G8UkTeEZHDIvKk89gFnEczPOnUf0dElkSqf7MxVb+ikYj8s4icFZF9E8oWiMivna//r0UkzykXEfmO0689InLFhGPucuofFpG7JpRfKSJ7nWO+IxF+3rKIVIjIKyJy0Pn+/It46qOIpIrIuyKy2+nff3PKZ/0zNNuf00gSEb+I7BKR55330dM/dR4Vaq/IvIBVwErgVaBmQnk1sBtIASqBI4Qeo+B3ti8Bkp061c4xTwFbnO1/Av4PZ/uLwD8521uAJ73ud5ivw5T9isYX8HHgCmDfhLJvAvc72/cDDzvbtwAvEHpK7EeAd5zyBcBR5/95znaes+9d4BrnmBeAmyPcvxLgCmc7CzjkfE/GRR+dz8x0tpOAd5y4Z/UzNJef0wj/O94H/AR43nkfNf2zM5sIU9WDqloXZtdm4AlVHVLVY0A9sN551avqUVUdBp4ANjt/Fd4APO0c/zjw6QltPe5sPw1sjPRfyjMQtl8exzQlVX2dDz/hdeLXefLX/0ca8jahp8iWADcBv1bVdlXtAH4NbHL2ZavqWxr6if/RhLYiQlWbVPU9Z7sHOAiUESd9dOLsdd4mOS9l9j9Ds/o5dblb5xGRcuBW4AfO+7n8jnCtf5ZsokcZcGrC+wanbKryfKBTVUcnlZ/XlrO/y6kfTabqVyxZqKpNEPplDRQ55bP9tyxztieXe8IZUrmc0F//cdNHZ4jpfeAsoSR4hNn/DM2235H0j8B/AYLO+7n8jnCtf5ZsXCAivxGRfWFeF/pLINyZh86h/EJtRZNYiHGu5vPfMqJEJBP4OfBlVe2+UNUwZVHdR1UdU9XLgHJCf6mvukBMMdU/EfkUcFZVd04sDlPVs/659ljoRKaqN87hsAagYsL7cqDR2Q5X3kpo6CLg/GUysf54Ww0iEgBy+PAQkNcu1N9YcUZESlS1yRkmOuuUT9W3BmDDpPJXnfLyMPUjSkSSCCWaf1HVZ5ziuOojgKp2isirhK7ZzPZnaLY/p5FyLXC7iNwCpALZhM50oqd/kb6AZa9zF/Je5fwJAqs5/8LcUUIX5QLOdiUfXJhb7RzzM86/+PdFZ/sezr/495TX/Q3T/yn7Fa0vYAnnTxD4FudfPP+ms30r5188f9cpXwAcI3ThPM/ZXuDs2+7UHb94fkuE+yaErqP846TyuOgjUAjkOttpwO+AT832Z2guP6cefJ9u4IMJAlHTP89/gBPtBXyG0F8PQ8AZ4KUJ+/6a0DhyHRNm6hCa+XPI2ffXE8ovITTDp975pkpxylOd9/XO/ku87vcUX4uw/YrGF/BToAkYcf797iY0xv1b4LDz//FfqgI86vRrL+f/UfEfnH+XeuDfTyivAfY5x/x/OKt7RLB/1xEaFtkDvO+8bomXPgJrgV1O//YBX3fKZ/0zNNufUw++VzfwQbKJmv7ZcjXGGGNcZxMEjDHGuM6SjTHGGNdZsjHGGOM6SzbGGGNcZ8nGGGOM6yzZGGOMcZ0lG2OMMa77/wEVyf+df7rHTAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Deliverable 1.5\n",
    "# Visualize the value counts of APPLICATION_TYPE\n",
    "#From 19.3.3 Practice Encoding Categorical Variables\n",
    "\n",
    "#Pre Density Plot APPLICATION TYPE\n",
    "APP_TYPE.plot.density()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T3       27037\n",
       "T4        1542\n",
       "T6        1216\n",
       "T5        1173\n",
       "T19       1065\n",
       "T8         737\n",
       "T7         725\n",
       "T10        528\n",
       "Other      276\n",
       "Name: APPLICATION_TYPE, dtype: int64"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Determine which values to replace if counts are less than ...?\n",
    "#19.3.3 Practice Encoding Categorical Variables\n",
    "# Determine which values to replace\n",
    "replace_application = list(APP_TYPE[APP_TYPE < 500].index)\n",
    "\n",
    "# Replace in dataframe\n",
    "for app in replace_application:\n",
    "    app_modify_df.APPLICATION_TYPE = app_modify_df.APPLICATION_TYPE.replace(app,\"Other\")\n",
    "    \n",
    "# Check to make sure binning was successful\n",
    "app_modify_df.APPLICATION_TYPE.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x213093c6588>"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Post Density Plot APPLICATION TYPE\n",
    "APP_TYPE = app_modify_df.APPLICATION_TYPE.value_counts()\n",
    "APP_TYPE.plot.density()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C1000    17326\n",
      "C2000     6074\n",
      "C1200     4837\n",
      "C3000     1918\n",
      "C2100     1883\n",
      "         ...  \n",
      "C4200        1\n",
      "C1370        1\n",
      "C1580        1\n",
      "C2561        1\n",
      "C2190        1\n",
      "Name: CLASSIFICATION, Length: 71, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Deliverable 1.4\n",
    "# Look at CLASSIFICATION value counts for binning\n",
    "CLASS = app_modify_df.CLASSIFICATION.value_counts()\n",
    "print(CLASS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2130ae3f1c8>"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Deliverable 1.5\n",
    "# Visualize the value counts of CLASSIFICATION\n",
    "#From 19.3.3 Practice Encoding Categorical Variables\n",
    "\n",
    "#Pre Density Plot CLASSIFICATION\n",
    "CLASS.plot.density()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "C1000    17326\n",
       "C2000     6074\n",
       "C1200     4837\n",
       "Other     2261\n",
       "C3000     1918\n",
       "C2100     1883\n",
       "Name: CLASSIFICATION, dtype: int64"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Determine which values to replace if counts are less than ..?\n",
    "#19.3.3 Practice Encoding Categorical Variables\n",
    "# Determine which values to replace\n",
    "replace_class = list(CLASS[CLASS < 1000].index)\n",
    "\n",
    "# Replace in dataframe\n",
    "for cls in replace_class:\n",
    "    app_modify_df.CLASSIFICATION = app_modify_df.CLASSIFICATION.replace(cls,\"Other\")\n",
    "    \n",
    "# Check to make sure binning was successful\n",
    "app_modify_df.CLASSIFICATION.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2130aefa588>"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Post Density Plot CLASSIFICATION\n",
    "CLASS = app_modify_df.CLASSIFICATION.value_counts()\n",
    "CLASS.plot.density()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['APPLICATION_TYPE',\n",
       " 'AFFILIATION',\n",
       " 'CLASSIFICATION',\n",
       " 'USE_CASE',\n",
       " 'ORGANIZATION',\n",
       " 'INCOME_AMT',\n",
       " 'SPECIAL_CONSIDERATIONS']"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Deliverable 1.7\n",
    "# Generate our categorical variable lists\n",
    "application_cat = app_modify_df.dtypes[app_modify_df.dtypes == \"object\"].index.tolist()\n",
    "application_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>APPLICATION_TYPE_Other</th>\n",
       "      <th>APPLICATION_TYPE_T10</th>\n",
       "      <th>APPLICATION_TYPE_T19</th>\n",
       "      <th>APPLICATION_TYPE_T3</th>\n",
       "      <th>APPLICATION_TYPE_T4</th>\n",
       "      <th>APPLICATION_TYPE_T5</th>\n",
       "      <th>APPLICATION_TYPE_T6</th>\n",
       "      <th>APPLICATION_TYPE_T7</th>\n",
       "      <th>APPLICATION_TYPE_T8</th>\n",
       "      <th>AFFILIATION_CompanySponsored</th>\n",
       "      <th>...</th>\n",
       "      <th>INCOME_AMT_1-9999</th>\n",
       "      <th>INCOME_AMT_10000-24999</th>\n",
       "      <th>INCOME_AMT_100000-499999</th>\n",
       "      <th>INCOME_AMT_10M-50M</th>\n",
       "      <th>INCOME_AMT_1M-5M</th>\n",
       "      <th>INCOME_AMT_25000-99999</th>\n",
       "      <th>INCOME_AMT_50M+</th>\n",
       "      <th>INCOME_AMT_5M-10M</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS_N</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS_Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   APPLICATION_TYPE_Other  APPLICATION_TYPE_T10  APPLICATION_TYPE_T19  \\\n",
       "0                     0.0                   1.0                   0.0   \n",
       "1                     0.0                   0.0                   0.0   \n",
       "2                     0.0                   0.0                   0.0   \n",
       "3                     0.0                   0.0                   0.0   \n",
       "4                     0.0                   0.0                   0.0   \n",
       "\n",
       "   APPLICATION_TYPE_T3  APPLICATION_TYPE_T4  APPLICATION_TYPE_T5  \\\n",
       "0                  0.0                  0.0                  0.0   \n",
       "1                  1.0                  0.0                  0.0   \n",
       "2                  0.0                  0.0                  1.0   \n",
       "3                  1.0                  0.0                  0.0   \n",
       "4                  1.0                  0.0                  0.0   \n",
       "\n",
       "   APPLICATION_TYPE_T6  APPLICATION_TYPE_T7  APPLICATION_TYPE_T8  \\\n",
       "0                  0.0                  0.0                  0.0   \n",
       "1                  0.0                  0.0                  0.0   \n",
       "2                  0.0                  0.0                  0.0   \n",
       "3                  0.0                  0.0                  0.0   \n",
       "4                  0.0                  0.0                  0.0   \n",
       "\n",
       "   AFFILIATION_CompanySponsored  ...  INCOME_AMT_1-9999  \\\n",
       "0                           0.0  ...                0.0   \n",
       "1                           0.0  ...                1.0   \n",
       "2                           1.0  ...                0.0   \n",
       "3                           1.0  ...                0.0   \n",
       "4                           0.0  ...                0.0   \n",
       "\n",
       "   INCOME_AMT_10000-24999  INCOME_AMT_100000-499999  INCOME_AMT_10M-50M  \\\n",
       "0                     0.0                       0.0                 0.0   \n",
       "1                     0.0                       0.0                 0.0   \n",
       "2                     0.0                       0.0                 0.0   \n",
       "3                     1.0                       0.0                 0.0   \n",
       "4                     0.0                       1.0                 0.0   \n",
       "\n",
       "   INCOME_AMT_1M-5M  INCOME_AMT_25000-99999  INCOME_AMT_50M+  \\\n",
       "0               0.0                     0.0              0.0   \n",
       "1               0.0                     0.0              0.0   \n",
       "2               0.0                     0.0              0.0   \n",
       "3               0.0                     0.0              0.0   \n",
       "4               0.0                     0.0              0.0   \n",
       "\n",
       "   INCOME_AMT_5M-10M  SPECIAL_CONSIDERATIONS_N  SPECIAL_CONSIDERATIONS_Y  \n",
       "0                0.0                       1.0                       0.0  \n",
       "1                0.0                       1.0                       0.0  \n",
       "2                0.0                       1.0                       0.0  \n",
       "3                0.0                       1.0                       0.0  \n",
       "4                0.0                       1.0                       0.0  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Deliverable 1.8\n",
    "# Create a OneHotEncoder instance\n",
    "enc = OneHotEncoder(sparse=False)\n",
    "\n",
    "# Fit and transform the OneHotEncoder using the categorical variable list\n",
    "encode_df = pd.DataFrame(enc.fit_transform(app_modify_df[application_cat]))\n",
    "\n",
    "# Add the encoded variable names to the dataframe\n",
    "encode_df.columns = enc.get_feature_names(application_cat)\n",
    "encode_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATUS</th>\n",
       "      <th>ASK_AMT</th>\n",
       "      <th>IS_SUCCESSFUL</th>\n",
       "      <th>APPLICATION_TYPE_Other</th>\n",
       "      <th>APPLICATION_TYPE_T10</th>\n",
       "      <th>APPLICATION_TYPE_T19</th>\n",
       "      <th>APPLICATION_TYPE_T3</th>\n",
       "      <th>APPLICATION_TYPE_T4</th>\n",
       "      <th>APPLICATION_TYPE_T5</th>\n",
       "      <th>APPLICATION_TYPE_T6</th>\n",
       "      <th>...</th>\n",
       "      <th>INCOME_AMT_1-9999</th>\n",
       "      <th>INCOME_AMT_10000-24999</th>\n",
       "      <th>INCOME_AMT_100000-499999</th>\n",
       "      <th>INCOME_AMT_10M-50M</th>\n",
       "      <th>INCOME_AMT_1M-5M</th>\n",
       "      <th>INCOME_AMT_25000-99999</th>\n",
       "      <th>INCOME_AMT_50M+</th>\n",
       "      <th>INCOME_AMT_5M-10M</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS_N</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS_Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>108590</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>6692</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>142590</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   STATUS  ASK_AMT  IS_SUCCESSFUL  APPLICATION_TYPE_Other  \\\n",
       "0       1     5000              1                     0.0   \n",
       "1       1   108590              1                     0.0   \n",
       "2       1     5000              0                     0.0   \n",
       "3       1     6692              1                     0.0   \n",
       "4       1   142590              1                     0.0   \n",
       "\n",
       "   APPLICATION_TYPE_T10  APPLICATION_TYPE_T19  APPLICATION_TYPE_T3  \\\n",
       "0                   1.0                   0.0                  0.0   \n",
       "1                   0.0                   0.0                  1.0   \n",
       "2                   0.0                   0.0                  0.0   \n",
       "3                   0.0                   0.0                  1.0   \n",
       "4                   0.0                   0.0                  1.0   \n",
       "\n",
       "   APPLICATION_TYPE_T4  APPLICATION_TYPE_T5  APPLICATION_TYPE_T6  ...  \\\n",
       "0                  0.0                  0.0                  0.0  ...   \n",
       "1                  0.0                  0.0                  0.0  ...   \n",
       "2                  0.0                  1.0                  0.0  ...   \n",
       "3                  0.0                  0.0                  0.0  ...   \n",
       "4                  0.0                  0.0                  0.0  ...   \n",
       "\n",
       "   INCOME_AMT_1-9999  INCOME_AMT_10000-24999  INCOME_AMT_100000-499999  \\\n",
       "0                0.0                     0.0                       0.0   \n",
       "1                1.0                     0.0                       0.0   \n",
       "2                0.0                     0.0                       0.0   \n",
       "3                0.0                     1.0                       0.0   \n",
       "4                0.0                     0.0                       1.0   \n",
       "\n",
       "   INCOME_AMT_10M-50M  INCOME_AMT_1M-5M  INCOME_AMT_25000-99999  \\\n",
       "0                 0.0               0.0                     0.0   \n",
       "1                 0.0               0.0                     0.0   \n",
       "2                 0.0               0.0                     0.0   \n",
       "3                 0.0               0.0                     0.0   \n",
       "4                 0.0               0.0                     0.0   \n",
       "\n",
       "   INCOME_AMT_50M+  INCOME_AMT_5M-10M  SPECIAL_CONSIDERATIONS_N  \\\n",
       "0              0.0                0.0                       1.0   \n",
       "1              0.0                0.0                       1.0   \n",
       "2              0.0                0.0                       1.0   \n",
       "3              0.0                0.0                       1.0   \n",
       "4              0.0                0.0                       1.0   \n",
       "\n",
       "   SPECIAL_CONSIDERATIONS_Y  \n",
       "0                       0.0  \n",
       "1                       0.0  \n",
       "2                       0.0  \n",
       "3                       0.0  \n",
       "4                       0.0  \n",
       "\n",
       "[5 rows x 44 columns]"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge one-hot encoded features and drop the originals\n",
    "app_merge_df = app_modify_df.merge(encode_df,left_index=True, right_index=True)\n",
    "app_merge_df = app_merge_df.drop(application_cat,1)\n",
    "app_merge_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split our preprocessed data into our features and target arrays\n",
    "x = app_merge_df.drop(columns=\"IS_SUCCESSFUL\").values\n",
    "y = app_merge_df.IS_SUCCESSFUL.values\n",
    "\n",
    "# Split the preprocessed data into a training and testing dataset\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a StandardScaler instances\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the StandardScaler\n",
    "x_scaler = scaler.fit(x_train)\n",
    "\n",
    "# Scale the data\n",
    "x_train_scaled = x_scaler.transform(x_train)\n",
    "x_test_scaled = x_scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train_scaled[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set number of hidden node ~ 2 x number of features.\n",
    "2 x 43 = 86\n",
    "\n",
    "https://machinelearningmastery.com/how-to-configure-the-number-of-layers-and-nodes-in-a-neural-network/\n",
    "\n",
    "https://stats.stackexchange.com/questions/181/how-to-choose-the-number-of-hidden-layers-and-nodes-in-a-feedforward-neural-netw#:~:text=The%20number%20of%20hidden%20neurons,size%20of%20the%20input%20layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deliverable 2: Compile, Train and Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_9 (Dense)              (None, 86)                3784      \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 43)                3741      \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 1)                 44        \n",
      "=================================================================\n",
      "Total params: 7,569\n",
      "Trainable params: 7,569\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Deliverable 2.2, 2.3, 2.4, 2.5, 2.6\n",
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "number_input_features = len(x_train_scaled[0])\n",
    "hidden_nodes_layer1 = 86\n",
    "hidden_nodes_layer2 = 43\n",
    "\n",
    "nn = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"relu\"))\n",
    "\n",
    "# Second hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"relu\"))\n",
    "\n",
    "# Output layer\n",
    "nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Deliverable 2.7\n",
    "# Compile the model\n",
    "#19.5.3 Support Vector Machine Vs. Deep Learning Model\n",
    "# Compile the Sequential model together and customize metrics\n",
    "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Deliverable 2.8\n",
    "#19.6.1 Checkpoints Are Not Just for Video Games\n",
    "\n",
    "# Import checkpoint dependencies\n",
    "import os\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# Define the checkpoint path and filenames\n",
    "os.makedirs(\"checkpoints/\",exist_ok=True)\n",
    "checkpoint_path = \"checkpoints/weights.{epoch:02d}.hdf5\"\n",
    "\n",
    "# Create a callback that saves the model's weights every 5 epochs\n",
    "cp_callback = ModelCheckpoint(\n",
    "    filepath=checkpoint_path,\n",
    "    verbose=1,\n",
    "    save_weights_only=True,\n",
    "    save_freq=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "  1/804 [..............................] - ETA: 0s - loss: 0.7752 - accuracy: 0.4375WARNING:tensorflow:Callbacks method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_begin` time: 0.0010s). Check your callbacks.\n",
      "804/804 [==============================] - 0s 455us/step - loss: 0.5702 - accuracy: 0.7242\n",
      "Epoch 2/50\n",
      "115/804 [===>..........................] - ETA: 0s - loss: 0.5560 - accuracy: 0.7272\n",
      "Epoch 00002: saving model to checkpoints\\weights.02.hdf5\n",
      "804/804 [==============================] - 0s 463us/step - loss: 0.5555 - accuracy: 0.7303\n",
      "Epoch 3/50\n",
      "343/804 [===========>..................] - ETA: 0s - loss: 0.5517 - accuracy: 0.7318\n",
      "Epoch 00003: saving model to checkpoints\\weights.03.hdf5\n",
      "804/804 [==============================] - 0s 453us/step - loss: 0.5527 - accuracy: 0.7318\n",
      "Epoch 4/50\n",
      "515/804 [==================>...........] - ETA: 0s - loss: 0.5483 - accuracy: 0.7375\n",
      "Epoch 00004: saving model to checkpoints\\weights.04.hdf5\n",
      "804/804 [==============================] - 0s 485us/step - loss: 0.5510 - accuracy: 0.7350\n",
      "Epoch 5/50\n",
      "690/804 [========================>.....] - ETA: 0s - loss: 0.5499 - accuracy: 0.7324\n",
      "Epoch 00005: saving model to checkpoints\\weights.05.hdf5\n",
      "804/804 [==============================] - 0s 450us/step - loss: 0.5497 - accuracy: 0.7340\n",
      "Epoch 6/50\n",
      "804/804 [==============================] - 0s 439us/step - loss: 0.5480 - accuracy: 0.7351\n",
      "Epoch 7/50\n",
      "116/804 [===>..........................] - ETA: 0s - loss: 0.5504 - accuracy: 0.7290\n",
      "Epoch 00007: saving model to checkpoints\\weights.07.hdf5\n",
      "804/804 [==============================] - 0s 452us/step - loss: 0.5473 - accuracy: 0.7346\n",
      "Epoch 8/50\n",
      "346/804 [===========>..................] - ETA: 0s - loss: 0.5445 - accuracy: 0.7350\n",
      "Epoch 00008: saving model to checkpoints\\weights.08.hdf5\n",
      "804/804 [==============================] - 0s 449us/step - loss: 0.5471 - accuracy: 0.7352\n",
      "Epoch 9/50\n",
      "464/804 [================>.............] - ETA: 0s - loss: 0.5422 - accuracy: 0.7412\n",
      "Epoch 00009: saving model to checkpoints\\weights.09.hdf5\n",
      "804/804 [==============================] - 0s 480us/step - loss: 0.5467 - accuracy: 0.7359\n",
      "Epoch 10/50\n",
      "688/804 [========================>.....] - ETA: 0s - loss: 0.5469 - accuracy: 0.7344\n",
      "Epoch 00010: saving model to checkpoints\\weights.10.hdf5\n",
      "804/804 [==============================] - 0s 455us/step - loss: 0.5456 - accuracy: 0.7353\n",
      "Epoch 11/50\n",
      "804/804 [==============================] - 0s 442us/step - loss: 0.5453 - accuracy: 0.7363\n",
      "Epoch 12/50\n",
      "115/804 [===>..........................] - ETA: 0s - loss: 0.5438 - accuracy: 0.7364\n",
      "Epoch 00012: saving model to checkpoints\\weights.12.hdf5\n",
      "804/804 [==============================] - 0s 458us/step - loss: 0.5453 - accuracy: 0.7352\n",
      "Epoch 13/50\n",
      "340/804 [===========>..................] - ETA: 0s - loss: 0.5353 - accuracy: 0.7442\n",
      "Epoch 00013: saving model to checkpoints\\weights.13.hdf5\n",
      "804/804 [==============================] - 0s 453us/step - loss: 0.5444 - accuracy: 0.7362\n",
      "Epoch 14/50\n",
      "459/804 [================>.............] - ETA: 0s - loss: 0.5423 - accuracy: 0.7376\n",
      "Epoch 00014: saving model to checkpoints\\weights.14.hdf5\n",
      "804/804 [==============================] - 0s 453us/step - loss: 0.5438 - accuracy: 0.7372\n",
      "Epoch 15/50\n",
      "743/804 [==========================>...] - ETA: 0s - loss: 0.5430 - accuracy: 0.7357\n",
      "Epoch 00015: saving model to checkpoints\\weights.15.hdf5\n",
      "804/804 [==============================] - 0s 484us/step - loss: 0.5434 - accuracy: 0.7356\n",
      "Epoch 16/50\n",
      "804/804 [==============================] - 0s 448us/step - loss: 0.5428 - accuracy: 0.7380\n",
      "Epoch 17/50\n",
      "116/804 [===>..........................] - ETA: 0s - loss: 0.5426 - accuracy: 0.7357\n",
      "Epoch 00017: saving model to checkpoints\\weights.17.hdf5\n",
      "804/804 [==============================] - 0s 455us/step - loss: 0.5421 - accuracy: 0.7378\n",
      "Epoch 18/50\n",
      "328/804 [===========>..................] - ETA: 0s - loss: 0.5362 - accuracy: 0.7432\n",
      "Epoch 00018: saving model to checkpoints\\weights.18.hdf5\n",
      "804/804 [==============================] - 0s 479us/step - loss: 0.5422 - accuracy: 0.7376\n",
      "Epoch 19/50\n",
      "437/804 [===============>..............] - ETA: 0s - loss: 0.5373 - accuracy: 0.7426\n",
      "Epoch 00019: saving model to checkpoints\\weights.19.hdf5\n",
      "804/804 [==============================] - 0s 470us/step - loss: 0.5421 - accuracy: 0.7386\n",
      "Epoch 20/50\n",
      "627/804 [======================>.......] - ETA: 0s - loss: 0.5398 - accuracy: 0.7412\n",
      "Epoch 00020: saving model to checkpoints\\weights.20.hdf5\n",
      "804/804 [==============================] - 0s 486us/step - loss: 0.5418 - accuracy: 0.7389\n",
      "Epoch 21/50\n",
      "804/804 [==============================] - 0s 445us/step - loss: 0.5420 - accuracy: 0.7374\n",
      "Epoch 22/50\n",
      "113/804 [===>..........................] - ETA: 0s - loss: 0.5397 - accuracy: 0.7403\n",
      "Epoch 00022: saving model to checkpoints\\weights.22.hdf5\n",
      "804/804 [==============================] - 0s 453us/step - loss: 0.5412 - accuracy: 0.7365\n",
      "Epoch 23/50\n",
      "227/804 [=======>......................] - ETA: 0s - loss: 0.5375 - accuracy: 0.7424\n",
      "Epoch 00023: saving model to checkpoints\\weights.23.hdf5\n",
      "804/804 [==============================] - 0s 458us/step - loss: 0.5409 - accuracy: 0.7385\n",
      "Epoch 24/50\n",
      "457/804 [================>.............] - ETA: 0s - loss: 0.5399 - accuracy: 0.7385\n",
      "Epoch 00024: saving model to checkpoints\\weights.24.hdf5\n",
      "804/804 [==============================] - 0s 454us/step - loss: 0.5406 - accuracy: 0.7371\n",
      "Epoch 25/50\n",
      "640/804 [======================>.......] - ETA: 0s - loss: 0.5391 - accuracy: 0.7420\n",
      "Epoch 00025: saving model to checkpoints\\weights.25.hdf5\n",
      "804/804 [==============================] - 0s 479us/step - loss: 0.5410 - accuracy: 0.7389\n",
      "Epoch 26/50\n",
      "804/804 [==============================] - 0s 445us/step - loss: 0.5405 - accuracy: 0.7392\n",
      "Epoch 27/50\n",
      "  1/804 [..............................] - ETA: 0s - loss: 0.4689 - accuracy: 0.8125\n",
      "Epoch 00027: saving model to checkpoints\\weights.27.hdf5\n",
      "804/804 [==============================] - 0s 455us/step - loss: 0.5402 - accuracy: 0.7384\n",
      "Epoch 28/50\n",
      "230/804 [=======>......................] - ETA: 0s - loss: 0.5381 - accuracy: 0.7391\n",
      "Epoch 00028: saving model to checkpoints\\weights.28.hdf5\n",
      "804/804 [==============================] - 0s 456us/step - loss: 0.5402 - accuracy: 0.7385\n",
      "Epoch 29/50\n",
      "448/804 [===============>..............] - ETA: 0s - loss: 0.5364 - accuracy: 0.7418\n",
      "Epoch 00029: saving model to checkpoints\\weights.29.hdf5\n",
      "804/804 [==============================] - 0s 459us/step - loss: 0.5398 - accuracy: 0.7379\n",
      "Epoch 30/50\n",
      "636/804 [======================>.......] - ETA: 0s - loss: 0.5377 - accuracy: 0.7396\n",
      "Epoch 00030: saving model to checkpoints\\weights.30.hdf5\n",
      "804/804 [==============================] - 0s 478us/step - loss: 0.5393 - accuracy: 0.7392\n",
      "Epoch 31/50\n",
      "804/804 [==============================] - 0s 448us/step - loss: 0.5395 - accuracy: 0.7396\n",
      "Epoch 32/50\n",
      "  1/804 [..............................] - ETA: 0s - loss: 0.6300 - accuracy: 0.6250\n",
      "Epoch 00032: saving model to checkpoints\\weights.32.hdf5\n",
      "804/804 [==============================] - 0s 450us/step - loss: 0.5391 - accuracy: 0.7388\n",
      "Epoch 33/50\n",
      "198/804 [======>.......................] - ETA: 0s - loss: 0.5299 - accuracy: 0.7454\n",
      "Epoch 00033: saving model to checkpoints\\weights.33.hdf5\n",
      "804/804 [==============================] - 0s 478us/step - loss: 0.5391 - accuracy: 0.7390\n",
      "Epoch 34/50\n",
      "458/804 [================>.............] - ETA: 0s - loss: 0.5395 - accuracy: 0.7372\n",
      "Epoch 00034: saving model to checkpoints\\weights.34.hdf5\n",
      "804/804 [==============================] - 0s 450us/step - loss: 0.5390 - accuracy: 0.7381\n",
      "Epoch 35/50\n",
      "657/804 [=======================>......] - ETA: 0s - loss: 0.5383 - accuracy: 0.7393\n",
      "Epoch 00035: saving model to checkpoints\\weights.35.hdf5\n",
      "804/804 [==============================] - 0s 486us/step - loss: 0.5387 - accuracy: 0.7392\n",
      "Epoch 36/50\n",
      "804/804 [==============================] - 0s 444us/step - loss: 0.5386 - accuracy: 0.7380\n",
      "Epoch 37/50\n",
      "  1/804 [..............................] - ETA: 0s - loss: 0.4189 - accuracy: 0.8125\n",
      "Epoch 00037: saving model to checkpoints\\weights.37.hdf5\n",
      "804/804 [==============================] - 0s 458us/step - loss: 0.5385 - accuracy: 0.7400\n",
      "Epoch 38/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "229/804 [=======>......................] - ETA: 0s - loss: 0.5393 - accuracy: 0.7406\n",
      "Epoch 00038: saving model to checkpoints\\weights.38.hdf5\n",
      "804/804 [==============================] - 0s 454us/step - loss: 0.5386 - accuracy: 0.7403\n",
      "Epoch 39/50\n",
      "345/804 [===========>..................] - ETA: 0s - loss: 0.5354 - accuracy: 0.7408\n",
      "Epoch 00039: saving model to checkpoints\\weights.39.hdf5\n",
      "804/804 [==============================] - 0s 453us/step - loss: 0.5376 - accuracy: 0.7400\n",
      "Epoch 40/50\n",
      "575/804 [====================>.........] - ETA: 0s - loss: 0.5379 - accuracy: 0.7374\n",
      "Epoch 00040: saving model to checkpoints\\weights.40.hdf5\n",
      "804/804 [==============================] - 0s 456us/step - loss: 0.5382 - accuracy: 0.7380\n",
      "Epoch 41/50\n",
      "804/804 [==============================] - 0s 473us/step - loss: 0.5382 - accuracy: 0.7395\n",
      "Epoch 42/50\n",
      "  1/804 [..............................] - ETA: 0s - loss: 0.4814 - accuracy: 0.8438\n",
      "Epoch 00042: saving model to checkpoints\\weights.42.hdf5\n",
      "804/804 [==============================] - 0s 452us/step - loss: 0.5376 - accuracy: 0.7398\n",
      "Epoch 43/50\n",
      "116/804 [===>..........................] - ETA: 0s - loss: 0.5402 - accuracy: 0.7406\n",
      "Epoch 00043: saving model to checkpoints\\weights.43.hdf5\n",
      "804/804 [==============================] - 0s 456us/step - loss: 0.5374 - accuracy: 0.7400\n",
      "Epoch 44/50\n",
      "348/804 [===========>..................] - ETA: 0s - loss: 0.5357 - accuracy: 0.7413\n",
      "Epoch 00044: saving model to checkpoints\\weights.44.hdf5\n",
      "804/804 [==============================] - 0s 447us/step - loss: 0.5379 - accuracy: 0.7399\n",
      "Epoch 45/50\n",
      "561/804 [===================>..........] - ETA: 0s - loss: 0.5416 - accuracy: 0.7384\n",
      "Epoch 00045: saving model to checkpoints\\weights.45.hdf5\n",
      "804/804 [==============================] - 0s 458us/step - loss: 0.5376 - accuracy: 0.7413\n",
      "Epoch 46/50\n",
      "804/804 [==============================] - 0s 475us/step - loss: 0.5371 - accuracy: 0.7400\n",
      "Epoch 47/50\n",
      "  1/804 [..............................] - ETA: 0s - loss: 0.4991 - accuracy: 0.7500\n",
      "Epoch 00047: saving model to checkpoints\\weights.47.hdf5\n",
      "804/804 [==============================] - 0s 454us/step - loss: 0.5373 - accuracy: 0.7404\n",
      "Epoch 48/50\n",
      "116/804 [===>..........................] - ETA: 0s - loss: 0.5382 - accuracy: 0.7408\n",
      "Epoch 00048: saving model to checkpoints\\weights.48.hdf5\n",
      "804/804 [==============================] - 0s 448us/step - loss: 0.5371 - accuracy: 0.7400\n",
      "Epoch 49/50\n",
      "340/804 [===========>..................] - ETA: 0s - loss: 0.5353 - accuracy: 0.7423\n",
      "Epoch 00049: saving model to checkpoints\\weights.49.hdf5\n",
      "804/804 [==============================] - 0s 453us/step - loss: 0.5366 - accuracy: 0.7391\n",
      "Epoch 50/50\n",
      "579/804 [====================>.........] - ETA: 0s - loss: 0.5371 - accuracy: 0.7400\n",
      "Epoch 00050: saving model to checkpoints\\weights.50.hdf5\n",
      "804/804 [==============================] - 0s 450us/step - loss: 0.5377 - accuracy: 0.7389\n"
     ]
    }
   ],
   "source": [
    "#Deliverable 2.7\n",
    "# Train the model\n",
    "fit_model = nn.fit(x_train_scaled, y_train, epochs=50,callbacks=[cp_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 - 0s - loss: 0.5563 - accuracy: 0.7226\n",
      "Loss: 0.5563138127326965, Accuracy: 0.7225655913352966\n"
     ]
    }
   ],
   "source": [
    "#Deliverable 2.9\n",
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn.evaluate(x_test_scaled,y_test,verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Deliverable 2.10\n",
    "#Save and export your results to an HDF5 file, and name it \"AlphabetSoupCharity.h5\"\n",
    "# Export our model to HDF5 file\n",
    "nn.save(\"AlphabetSoupCharity.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deliverable 3: Optimize the Model (20 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimize your model in order to achieve a target predictive accuracy higher than 75% by using any or all of the following:\n",
    "\n",
    "* Adjusting the input data to ensure that there are no variables or outliers that are causing confusion in the model, such as:\n",
    "    * Dropping more or fewer columns.\n",
    "    * Creating more bins for rare occurrences in columns.\n",
    "    * Increasing or decreasing the number of values for each bin.\n",
    "* Adding more neurons to a hidden layer.\n",
    "* Adding more hidden layers.\n",
    "* Using different activation functions for the hidden layers.\n",
    "* Adding or reducing the number of epochs to the training regimen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "804/804 [==============================] - 0s 444us/step - loss: 0.5247 - accuracy: 0.7458\n",
      "Epoch 2/100\n",
      "804/804 [==============================] - 0s 440us/step - loss: 0.5247 - accuracy: 0.7462\n",
      "Epoch 3/100\n",
      "804/804 [==============================] - 0s 440us/step - loss: 0.5251 - accuracy: 0.7452\n",
      "Epoch 4/100\n",
      "804/804 [==============================] - 0s 442us/step - loss: 0.5251 - accuracy: 0.7456\n",
      "Epoch 5/100\n",
      "804/804 [==============================] - 0s 442us/step - loss: 0.5253 - accuracy: 0.7457\n",
      "Epoch 6/100\n",
      "804/804 [==============================] - 0s 443us/step - loss: 0.5261 - accuracy: 0.7457\n",
      "Epoch 7/100\n",
      "804/804 [==============================] - 0s 450us/step - loss: 0.5256 - accuracy: 0.7461\n",
      "Epoch 8/100\n",
      "804/804 [==============================] - 0s 445us/step - loss: 0.5253 - accuracy: 0.7453\n",
      "Epoch 9/100\n",
      "804/804 [==============================] - 0s 442us/step - loss: 0.5255 - accuracy: 0.7450\n",
      "Epoch 10/100\n",
      "804/804 [==============================] - 0s 444us/step - loss: 0.5255 - accuracy: 0.7459\n",
      "Epoch 11/100\n",
      "804/804 [==============================] - 0s 445us/step - loss: 0.5258 - accuracy: 0.7460\n",
      "Epoch 12/100\n",
      "804/804 [==============================] - 0s 448us/step - loss: 0.5260 - accuracy: 0.7459\n",
      "Epoch 13/100\n",
      "804/804 [==============================] - 0s 444us/step - loss: 0.5257 - accuracy: 0.7460\n",
      "Epoch 14/100\n",
      "804/804 [==============================] - 0s 449us/step - loss: 0.5258 - accuracy: 0.7454\n",
      "Epoch 15/100\n",
      "804/804 [==============================] - 0s 448us/step - loss: 0.5252 - accuracy: 0.7462\n",
      "Epoch 16/100\n",
      "804/804 [==============================] - 0s 450us/step - loss: 0.5256 - accuracy: 0.7461\n",
      "Epoch 17/100\n",
      "804/804 [==============================] - 0s 455us/step - loss: 0.5255 - accuracy: 0.7462\n",
      "Epoch 18/100\n",
      "804/804 [==============================] - 0s 448us/step - loss: 0.5255 - accuracy: 0.7458\n",
      "Epoch 19/100\n",
      "804/804 [==============================] - 0s 459us/step - loss: 0.5265 - accuracy: 0.7458\n",
      "Epoch 20/100\n",
      "804/804 [==============================] - 0s 456us/step - loss: 0.5255 - accuracy: 0.7459\n",
      "Epoch 21/100\n",
      "804/804 [==============================] - 0s 450us/step - loss: 0.5258 - accuracy: 0.7457\n",
      "Epoch 22/100\n",
      "804/804 [==============================] - 0s 483us/step - loss: 0.5273 - accuracy: 0.7458\n",
      "Epoch 23/100\n",
      "804/804 [==============================] - 0s 471us/step - loss: 0.5341 - accuracy: 0.7451\n",
      "Epoch 24/100\n",
      "804/804 [==============================] - 0s 453us/step - loss: 0.5886 - accuracy: 0.7452\n",
      "Epoch 25/100\n",
      "804/804 [==============================] - 0s 453us/step - loss: 0.5259 - accuracy: 0.7459\n",
      "Epoch 26/100\n",
      "804/804 [==============================] - 0s 453us/step - loss: 0.5252 - accuracy: 0.7461\n",
      "Epoch 27/100\n",
      "804/804 [==============================] - 0s 452us/step - loss: 0.5250 - accuracy: 0.7460\n",
      "Epoch 28/100\n",
      "804/804 [==============================] - 0s 455us/step - loss: 0.5250 - accuracy: 0.7457\n",
      "Epoch 29/100\n",
      "804/804 [==============================] - 0s 455us/step - loss: 0.5252 - accuracy: 0.7463\n",
      "Epoch 30/100\n",
      "804/804 [==============================] - 0s 452us/step - loss: 0.5254 - accuracy: 0.7458\n",
      "Epoch 31/100\n",
      "804/804 [==============================] - 0s 453us/step - loss: 0.5252 - accuracy: 0.7455\n",
      "Epoch 32/100\n",
      "804/804 [==============================] - 0s 454us/step - loss: 0.5258 - accuracy: 0.7455\n",
      "Epoch 33/100\n",
      "804/804 [==============================] - 0s 460us/step - loss: 0.5259 - accuracy: 0.7458\n",
      "Epoch 34/100\n",
      "804/804 [==============================] - 0s 468us/step - loss: 0.5255 - accuracy: 0.7457\n",
      "Epoch 35/100\n",
      "804/804 [==============================] - 0s 453us/step - loss: 0.5255 - accuracy: 0.7449\n",
      "Epoch 36/100\n",
      "804/804 [==============================] - 0s 454us/step - loss: 0.5261 - accuracy: 0.7460\n",
      "Epoch 37/100\n",
      "804/804 [==============================] - 0s 460us/step - loss: 0.5257 - accuracy: 0.7456\n",
      "Epoch 38/100\n",
      "804/804 [==============================] - 0s 455us/step - loss: 0.5255 - accuracy: 0.7459\n",
      "Epoch 39/100\n",
      "804/804 [==============================] - 0s 455us/step - loss: 0.5261 - accuracy: 0.7461\n",
      "Epoch 40/100\n",
      "804/804 [==============================] - 0s 459us/step - loss: 0.5267 - accuracy: 0.7458\n",
      "Epoch 41/100\n",
      "804/804 [==============================] - 0s 459us/step - loss: 0.5255 - accuracy: 0.7453\n",
      "Epoch 42/100\n",
      "804/804 [==============================] - 0s 460us/step - loss: 0.5255 - accuracy: 0.7455\n",
      "Epoch 43/100\n",
      "804/804 [==============================] - 0s 456us/step - loss: 0.5253 - accuracy: 0.7455\n",
      "Epoch 44/100\n",
      "804/804 [==============================] - 0s 456us/step - loss: 0.5256 - accuracy: 0.7461\n",
      "Epoch 45/100\n",
      "804/804 [==============================] - 0s 454us/step - loss: 0.5267 - accuracy: 0.7457\n",
      "Epoch 46/100\n",
      "804/804 [==============================] - 0s 459us/step - loss: 0.5256 - accuracy: 0.7457\n",
      "Epoch 47/100\n",
      "804/804 [==============================] - 0s 459us/step - loss: 0.5278 - accuracy: 0.7455\n",
      "Epoch 48/100\n",
      "804/804 [==============================] - 0s 454us/step - loss: 0.5263 - accuracy: 0.7460\n",
      "Epoch 49/100\n",
      "804/804 [==============================] - 0s 463us/step - loss: 0.5268 - accuracy: 0.7458\n",
      "Epoch 50/100\n",
      "804/804 [==============================] - 0s 460us/step - loss: 0.5262 - accuracy: 0.7457\n",
      "Epoch 51/100\n",
      "804/804 [==============================] - 0s 464us/step - loss: 0.5259 - accuracy: 0.7463\n",
      "Epoch 52/100\n",
      "804/804 [==============================] - 0s 460us/step - loss: 0.5258 - accuracy: 0.7463\n",
      "Epoch 53/100\n",
      "804/804 [==============================] - 0s 456us/step - loss: 0.5261 - accuracy: 0.7463\n",
      "Epoch 54/100\n",
      "804/804 [==============================] - 0s 460us/step - loss: 0.5251 - accuracy: 0.7458\n",
      "Epoch 55/100\n",
      "804/804 [==============================] - 0s 458us/step - loss: 0.5255 - accuracy: 0.7462\n",
      "Epoch 56/100\n",
      "804/804 [==============================] - 0s 456us/step - loss: 0.5254 - accuracy: 0.7462\n",
      "Epoch 57/100\n",
      "804/804 [==============================] - 0s 465us/step - loss: 0.5252 - accuracy: 0.7462\n",
      "Epoch 58/100\n",
      "804/804 [==============================] - 0s 455us/step - loss: 0.5262 - accuracy: 0.7458\n",
      "Epoch 59/100\n",
      "804/804 [==============================] - 0s 454us/step - loss: 0.5276 - accuracy: 0.7458\n",
      "Epoch 60/100\n",
      "804/804 [==============================] - 0s 466us/step - loss: 0.5259 - accuracy: 0.7458\n",
      "Epoch 61/100\n",
      "804/804 [==============================] - 0s 494us/step - loss: 0.5282 - accuracy: 0.7456\n",
      "Epoch 62/100\n",
      "804/804 [==============================] - 0s 479us/step - loss: 0.5256 - accuracy: 0.7456\n",
      "Epoch 63/100\n",
      "804/804 [==============================] - 0s 452us/step - loss: 0.5252 - accuracy: 0.7458\n",
      "Epoch 64/100\n",
      "804/804 [==============================] - 0s 455us/step - loss: 0.5252 - accuracy: 0.7460\n",
      "Epoch 65/100\n",
      "804/804 [==============================] - 0s 501us/step - loss: 0.5258 - accuracy: 0.7465\n",
      "Epoch 66/100\n",
      "804/804 [==============================] - 0s 519us/step - loss: 0.5257 - accuracy: 0.7458\n",
      "Epoch 67/100\n",
      "804/804 [==============================] - 0s 461us/step - loss: 0.5255 - accuracy: 0.7455\n",
      "Epoch 68/100\n",
      "804/804 [==============================] - 0s 484us/step - loss: 0.5264 - accuracy: 0.7453\n",
      "Epoch 69/100\n",
      "804/804 [==============================] - 0s 456us/step - loss: 0.5254 - accuracy: 0.7456\n",
      "Epoch 70/100\n",
      "804/804 [==============================] - 0s 485us/step - loss: 0.5254 - accuracy: 0.7460\n",
      "Epoch 71/100\n",
      "804/804 [==============================] - 0s 464us/step - loss: 0.5266 - accuracy: 0.7456\n",
      "Epoch 72/100\n",
      "804/804 [==============================] - 0s 496us/step - loss: 0.5249 - accuracy: 0.7465\n",
      "Epoch 73/100\n",
      "804/804 [==============================] - 0s 456us/step - loss: 0.5253 - accuracy: 0.7454\n",
      "Epoch 74/100\n",
      "804/804 [==============================] - 0s 448us/step - loss: 0.5253 - accuracy: 0.7460\n",
      "Epoch 75/100\n",
      "804/804 [==============================] - 0s 461us/step - loss: 0.5266 - accuracy: 0.7453\n",
      "Epoch 76/100\n",
      "804/804 [==============================] - 0s 448us/step - loss: 0.6066 - accuracy: 0.7456\n",
      "Epoch 77/100\n",
      "804/804 [==============================] - 0s 447us/step - loss: 0.5255 - accuracy: 0.7460\n",
      "Epoch 78/100\n",
      "804/804 [==============================] - 0s 448us/step - loss: 0.5251 - accuracy: 0.7461\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "804/804 [==============================] - 0s 448us/step - loss: 0.5250 - accuracy: 0.7459\n",
      "Epoch 80/100\n",
      "804/804 [==============================] - 0s 448us/step - loss: 0.5251 - accuracy: 0.7453\n",
      "Epoch 81/100\n",
      "804/804 [==============================] - 0s 448us/step - loss: 0.5251 - accuracy: 0.7462\n",
      "Epoch 82/100\n",
      "804/804 [==============================] - 0s 455us/step - loss: 0.5254 - accuracy: 0.7459\n",
      "Epoch 83/100\n",
      "804/804 [==============================] - 0s 447us/step - loss: 0.5252 - accuracy: 0.7456\n",
      "Epoch 84/100\n",
      "804/804 [==============================] - 0s 448us/step - loss: 0.5251 - accuracy: 0.7462\n",
      "Epoch 85/100\n",
      "804/804 [==============================] - 0s 445us/step - loss: 0.5255 - accuracy: 0.7458\n",
      "Epoch 86/100\n",
      "804/804 [==============================] - 0s 452us/step - loss: 0.5255 - accuracy: 0.7461\n",
      "Epoch 87/100\n",
      "804/804 [==============================] - 0s 449us/step - loss: 0.5257 - accuracy: 0.7462\n",
      "Epoch 88/100\n",
      "804/804 [==============================] - 0s 447us/step - loss: 0.5261 - accuracy: 0.7457\n",
      "Epoch 89/100\n",
      "804/804 [==============================] - 0s 452us/step - loss: 0.5300 - accuracy: 0.7459\n",
      "Epoch 90/100\n",
      "804/804 [==============================] - 0s 447us/step - loss: 0.6021 - accuracy: 0.7457\n",
      "Epoch 91/100\n",
      "804/804 [==============================] - 0s 445us/step - loss: 0.5247 - accuracy: 0.7464\n",
      "Epoch 92/100\n",
      "804/804 [==============================] - 0s 447us/step - loss: 0.5247 - accuracy: 0.7457\n",
      "Epoch 93/100\n",
      "804/804 [==============================] - 0s 447us/step - loss: 0.5250 - accuracy: 0.7461\n",
      "Epoch 94/100\n",
      "804/804 [==============================] - 0s 448us/step - loss: 0.5250 - accuracy: 0.7463\n",
      "Epoch 95/100\n",
      "804/804 [==============================] - 0s 458us/step - loss: 0.5252 - accuracy: 0.7453\n",
      "Epoch 96/100\n",
      "804/804 [==============================] - 0s 444us/step - loss: 0.5256 - accuracy: 0.7465\n",
      "Epoch 97/100\n",
      "804/804 [==============================] - 0s 447us/step - loss: 0.5253 - accuracy: 0.7462\n",
      "Epoch 98/100\n",
      "804/804 [==============================] - 0s 447us/step - loss: 0.5261 - accuracy: 0.7456\n",
      "Epoch 99/100\n",
      "804/804 [==============================] - 0s 445us/step - loss: 0.5260 - accuracy: 0.7455\n",
      "Epoch 100/100\n",
      "804/804 [==============================] - 0s 445us/step - loss: 0.5258 - accuracy: 0.7460\n"
     ]
    }
   ],
   "source": [
    "# Attempt 1\n",
    "# Increase epochs from 50 to 100\n",
    "fit_model_attempt1 = nn.fit(x_train_scaled, y_train, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 - 0s - loss: 0.7391 - accuracy: 0.7256\n",
      "Attempt 1\n",
      "Loss: 0.739080011844635, Accuracy: 0.7255976796150208\n"
     ]
    }
   ],
   "source": [
    "# Attempt 1\n",
    "# Evaluate the model\n",
    "model_loss, model_accuracy = nn.evaluate(x_test_scaled,y_test,verbose=2)\n",
    "print(\"Attempt 1\")\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy\n",
    "\n",
    "Original: 0.7225655913352966\n",
    "\n",
    "Attempt 1 (Epoch = 100):  0.7255976796150208"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_12 (Dense)             (None, 172)               7568      \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 86)                14878     \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 1)                 87        \n",
      "=================================================================\n",
      "Total params: 22,533\n",
      "Trainable params: 22,533\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Attempt 2\n",
    "# Double number of nodes in hidden layers\n",
    "    # hidden_nodes_layer1 from 86 to 172\n",
    "    # hidden_nodes_layer2 from 43 to 86\n",
    "# maintain epoch = 100\n",
    "\n",
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "number_input_features = len(x_train_scaled[0])\n",
    "hidden_nodes_layer1 = 172\n",
    "hidden_nodes_layer2 = 86\n",
    "\n",
    "nn = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"relu\"))\n",
    "\n",
    "# Second hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"relu\"))\n",
    "\n",
    "# Output layer\n",
    "nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attempt 2\n",
    "# Double number of nodes in hidden layers\n",
    "# hidden_nodes_layer1 from 86 to 172\n",
    "# hidden_nodes_layer2 from 43 to 86\n",
    "# maintain epoch = 100\n",
    "\n",
    "# Compile\n",
    "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "804/804 [==============================] - 0s 515us/step - loss: 0.5677 - accuracy: 0.7239\n",
      "Epoch 2/100\n",
      "804/804 [==============================] - 0s 510us/step - loss: 0.5546 - accuracy: 0.7306\n",
      "Epoch 3/100\n",
      "804/804 [==============================] - 0s 515us/step - loss: 0.5515 - accuracy: 0.7322\n",
      "Epoch 4/100\n",
      "804/804 [==============================] - 0s 527us/step - loss: 0.5500 - accuracy: 0.7335\n",
      "Epoch 5/100\n",
      "804/804 [==============================] - 0s 547us/step - loss: 0.5489 - accuracy: 0.7346\n",
      "Epoch 6/100\n",
      "804/804 [==============================] - 0s 511us/step - loss: 0.5482 - accuracy: 0.7344\n",
      "Epoch 7/100\n",
      "804/804 [==============================] - 0s 512us/step - loss: 0.5477 - accuracy: 0.7352\n",
      "Epoch 8/100\n",
      "804/804 [==============================] - 0s 507us/step - loss: 0.5468 - accuracy: 0.7348\n",
      "Epoch 9/100\n",
      "804/804 [==============================] - 0s 507us/step - loss: 0.5461 - accuracy: 0.7361\n",
      "Epoch 10/100\n",
      "804/804 [==============================] - 0s 510us/step - loss: 0.5455 - accuracy: 0.7355\n",
      "Epoch 11/100\n",
      "804/804 [==============================] - 0s 507us/step - loss: 0.5450 - accuracy: 0.7372\n",
      "Epoch 12/100\n",
      "804/804 [==============================] - 0s 505us/step - loss: 0.5446 - accuracy: 0.7362\n",
      "Epoch 13/100\n",
      "804/804 [==============================] - 0s 516us/step - loss: 0.5442 - accuracy: 0.7374\n",
      "Epoch 14/100\n",
      "804/804 [==============================] - 0s 511us/step - loss: 0.5438 - accuracy: 0.7379\n",
      "Epoch 15/100\n",
      "804/804 [==============================] - 0s 509us/step - loss: 0.5437 - accuracy: 0.7377\n",
      "Epoch 16/100\n",
      "804/804 [==============================] - 0s 509us/step - loss: 0.5429 - accuracy: 0.7359\n",
      "Epoch 17/100\n",
      "804/804 [==============================] - 0s 510us/step - loss: 0.5427 - accuracy: 0.7372\n",
      "Epoch 18/100\n",
      "804/804 [==============================] - 0s 504us/step - loss: 0.5424 - accuracy: 0.7373\n",
      "Epoch 19/100\n",
      "804/804 [==============================] - 0s 504us/step - loss: 0.5421 - accuracy: 0.7378\n",
      "Epoch 20/100\n",
      "804/804 [==============================] - 0s 506us/step - loss: 0.5422 - accuracy: 0.7382\n",
      "Epoch 21/100\n",
      "804/804 [==============================] - 0s 514us/step - loss: 0.5414 - accuracy: 0.7369\n",
      "Epoch 22/100\n",
      "804/804 [==============================] - 0s 512us/step - loss: 0.5413 - accuracy: 0.7379\n",
      "Epoch 23/100\n",
      "804/804 [==============================] - 0s 507us/step - loss: 0.5410 - accuracy: 0.7373\n",
      "Epoch 24/100\n",
      "804/804 [==============================] - 0s 511us/step - loss: 0.5405 - accuracy: 0.7383\n",
      "Epoch 25/100\n",
      "804/804 [==============================] - 0s 511us/step - loss: 0.5406 - accuracy: 0.7382\n",
      "Epoch 26/100\n",
      "804/804 [==============================] - 0s 507us/step - loss: 0.5401 - accuracy: 0.7381\n",
      "Epoch 27/100\n",
      "804/804 [==============================] - 0s 509us/step - loss: 0.5398 - accuracy: 0.7388\n",
      "Epoch 28/100\n",
      "804/804 [==============================] - 0s 507us/step - loss: 0.5396 - accuracy: 0.7392\n",
      "Epoch 29/100\n",
      "804/804 [==============================] - 0s 530us/step - loss: 0.5395 - accuracy: 0.7393\n",
      "Epoch 30/100\n",
      "804/804 [==============================] - 0s 512us/step - loss: 0.5395 - accuracy: 0.7387\n",
      "Epoch 31/100\n",
      "804/804 [==============================] - 0s 512us/step - loss: 0.5390 - accuracy: 0.7392\n",
      "Epoch 32/100\n",
      "804/804 [==============================] - 0s 514us/step - loss: 0.5385 - accuracy: 0.7390\n",
      "Epoch 33/100\n",
      "804/804 [==============================] - 0s 509us/step - loss: 0.5388 - accuracy: 0.7397\n",
      "Epoch 34/100\n",
      "804/804 [==============================] - 0s 510us/step - loss: 0.5390 - accuracy: 0.7394\n",
      "Epoch 35/100\n",
      "804/804 [==============================] - 0s 512us/step - loss: 0.5383 - accuracy: 0.7395\n",
      "Epoch 36/100\n",
      "804/804 [==============================] - 0s 510us/step - loss: 0.5384 - accuracy: 0.7395\n",
      "Epoch 37/100\n",
      "804/804 [==============================] - 0s 514us/step - loss: 0.5383 - accuracy: 0.7404\n",
      "Epoch 38/100\n",
      "804/804 [==============================] - 0s 511us/step - loss: 0.5382 - accuracy: 0.7400\n",
      "Epoch 39/100\n",
      "804/804 [==============================] - 0s 511us/step - loss: 0.5384 - accuracy: 0.7404\n",
      "Epoch 40/100\n",
      "804/804 [==============================] - 0s 521us/step - loss: 0.5375 - accuracy: 0.7395\n",
      "Epoch 41/100\n",
      "804/804 [==============================] - 0s 519us/step - loss: 0.5378 - accuracy: 0.7398\n",
      "Epoch 42/100\n",
      "804/804 [==============================] - 0s 516us/step - loss: 0.5378 - accuracy: 0.7394\n",
      "Epoch 43/100\n",
      "804/804 [==============================] - 0s 546us/step - loss: 0.5370 - accuracy: 0.7399\n",
      "Epoch 44/100\n",
      "804/804 [==============================] - 0s 545us/step - loss: 0.5373 - accuracy: 0.7403\n",
      "Epoch 45/100\n",
      "804/804 [==============================] - 0s 512us/step - loss: 0.5371 - accuracy: 0.7402\n",
      "Epoch 46/100\n",
      "804/804 [==============================] - 0s 511us/step - loss: 0.5367 - accuracy: 0.7402\n",
      "Epoch 47/100\n",
      "804/804 [==============================] - 0s 511us/step - loss: 0.5363 - accuracy: 0.7395\n",
      "Epoch 48/100\n",
      "804/804 [==============================] - 0s 517us/step - loss: 0.5367 - accuracy: 0.7404\n",
      "Epoch 49/100\n",
      "804/804 [==============================] - 0s 517us/step - loss: 0.5370 - accuracy: 0.7405\n",
      "Epoch 50/100\n",
      "804/804 [==============================] - 0s 511us/step - loss: 0.5358 - accuracy: 0.7413\n",
      "Epoch 51/100\n",
      "804/804 [==============================] - 0s 517us/step - loss: 0.5366 - accuracy: 0.7404\n",
      "Epoch 52/100\n",
      "804/804 [==============================] - 0s 515us/step - loss: 0.5375 - accuracy: 0.7407\n",
      "Epoch 53/100\n",
      "804/804 [==============================] - 0s 516us/step - loss: 0.5361 - accuracy: 0.7413\n",
      "Epoch 54/100\n",
      "804/804 [==============================] - 0s 512us/step - loss: 0.5358 - accuracy: 0.7415\n",
      "Epoch 55/100\n",
      "804/804 [==============================] - 0s 517us/step - loss: 0.5366 - accuracy: 0.7407\n",
      "Epoch 56/100\n",
      "804/804 [==============================] - 0s 515us/step - loss: 0.5357 - accuracy: 0.7410\n",
      "Epoch 57/100\n",
      "804/804 [==============================] - 0s 523us/step - loss: 0.5359 - accuracy: 0.7414\n",
      "Epoch 58/100\n",
      "804/804 [==============================] - 0s 516us/step - loss: 0.5356 - accuracy: 0.7410\n",
      "Epoch 59/100\n",
      "804/804 [==============================] - 0s 512us/step - loss: 0.5356 - accuracy: 0.7410\n",
      "Epoch 60/100\n",
      "804/804 [==============================] - 0s 519us/step - loss: 0.5348 - accuracy: 0.7409\n",
      "Epoch 61/100\n",
      "804/804 [==============================] - 0s 531us/step - loss: 0.5356 - accuracy: 0.7407\n",
      "Epoch 62/100\n",
      "804/804 [==============================] - 0s 527us/step - loss: 0.5353 - accuracy: 0.7416\n",
      "Epoch 63/100\n",
      "804/804 [==============================] - 0s 520us/step - loss: 0.5353 - accuracy: 0.7407\n",
      "Epoch 64/100\n",
      "804/804 [==============================] - 0s 519us/step - loss: 0.5352 - accuracy: 0.7409\n",
      "Epoch 65/100\n",
      "804/804 [==============================] - 0s 527us/step - loss: 0.5349 - accuracy: 0.7408\n",
      "Epoch 66/100\n",
      "804/804 [==============================] - 0s 525us/step - loss: 0.5353 - accuracy: 0.7415\n",
      "Epoch 67/100\n",
      "804/804 [==============================] - 0s 520us/step - loss: 0.5350 - accuracy: 0.7411\n",
      "Epoch 68/100\n",
      "804/804 [==============================] - 0s 522us/step - loss: 0.5356 - accuracy: 0.7422\n",
      "Epoch 69/100\n",
      "804/804 [==============================] - 0s 530us/step - loss: 0.5346 - accuracy: 0.7417\n",
      "Epoch 70/100\n",
      "804/804 [==============================] - 0s 520us/step - loss: 0.5350 - accuracy: 0.7413\n",
      "Epoch 71/100\n",
      "804/804 [==============================] - 0s 521us/step - loss: 0.5350 - accuracy: 0.7421\n",
      "Epoch 72/100\n",
      "804/804 [==============================] - 0s 520us/step - loss: 0.5347 - accuracy: 0.7411\n",
      "Epoch 73/100\n",
      "804/804 [==============================] - 0s 519us/step - loss: 0.5341 - accuracy: 0.7415\n",
      "Epoch 74/100\n",
      "804/804 [==============================] - 0s 519us/step - loss: 0.5350 - accuracy: 0.7418\n",
      "Epoch 75/100\n",
      "804/804 [==============================] - 0s 517us/step - loss: 0.5348 - accuracy: 0.7406\n",
      "Epoch 76/100\n",
      "804/804 [==============================] - 0s 547us/step - loss: 0.5347 - accuracy: 0.7411\n",
      "Epoch 77/100\n",
      "804/804 [==============================] - 0s 522us/step - loss: 0.5347 - accuracy: 0.7411\n",
      "Epoch 78/100\n",
      "804/804 [==============================] - 0s 519us/step - loss: 0.5353 - accuracy: 0.7413\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "804/804 [==============================] - 0s 517us/step - loss: 0.5343 - accuracy: 0.7408\n",
      "Epoch 80/100\n",
      "804/804 [==============================] - 0s 516us/step - loss: 0.5342 - accuracy: 0.7417\n",
      "Epoch 81/100\n",
      "804/804 [==============================] - 0s 545us/step - loss: 0.5338 - accuracy: 0.7413\n",
      "Epoch 82/100\n",
      "804/804 [==============================] - 0s 535us/step - loss: 0.5337 - accuracy: 0.7423\n",
      "Epoch 83/100\n",
      "804/804 [==============================] - 0s 526us/step - loss: 0.5343 - accuracy: 0.7416\n",
      "Epoch 84/100\n",
      "804/804 [==============================] - 0s 520us/step - loss: 0.5341 - accuracy: 0.7414\n",
      "Epoch 85/100\n",
      "804/804 [==============================] - 0s 516us/step - loss: 0.5345 - accuracy: 0.7412\n",
      "Epoch 86/100\n",
      "804/804 [==============================] - 0s 517us/step - loss: 0.5337 - accuracy: 0.7406\n",
      "Epoch 87/100\n",
      "804/804 [==============================] - 0s 520us/step - loss: 0.5334 - accuracy: 0.7416\n",
      "Epoch 88/100\n",
      "804/804 [==============================] - 0s 517us/step - loss: 0.5338 - accuracy: 0.7416\n",
      "Epoch 89/100\n",
      "804/804 [==============================] - 0s 523us/step - loss: 0.5343 - accuracy: 0.7421\n",
      "Epoch 90/100\n",
      "804/804 [==============================] - 0s 523us/step - loss: 0.5359 - accuracy: 0.7413\n",
      "Epoch 91/100\n",
      "804/804 [==============================] - 0s 520us/step - loss: 0.5335 - accuracy: 0.7419\n",
      "Epoch 92/100\n",
      "804/804 [==============================] - 0s 525us/step - loss: 0.5329 - accuracy: 0.7418\n",
      "Epoch 93/100\n",
      "804/804 [==============================] - 0s 532us/step - loss: 0.5331 - accuracy: 0.7421\n",
      "Epoch 94/100\n",
      "804/804 [==============================] - 0s 533us/step - loss: 0.5339 - accuracy: 0.7426\n",
      "Epoch 95/100\n",
      "804/804 [==============================] - 0s 538us/step - loss: 0.5334 - accuracy: 0.7419\n",
      "Epoch 96/100\n",
      "804/804 [==============================] - 0s 553us/step - loss: 0.5333 - accuracy: 0.7421\n",
      "Epoch 97/100\n",
      "804/804 [==============================] - 0s 530us/step - loss: 0.5338 - accuracy: 0.7416\n",
      "Epoch 98/100\n",
      "804/804 [==============================] - 0s 528us/step - loss: 0.5331 - accuracy: 0.7421\n",
      "Epoch 99/100\n",
      "804/804 [==============================] - 0s 526us/step - loss: 0.5338 - accuracy: 0.7417\n",
      "Epoch 100/100\n",
      "804/804 [==============================] - 0s 541us/step - loss: 0.5334 - accuracy: 0.7416\n"
     ]
    }
   ],
   "source": [
    "# Attempt 2\n",
    "# Double number of nodes in hidden layers\n",
    "# hidden_nodes_layer1 from 86 to 172\n",
    "# hidden_nodes_layer2 from 43 to 86\n",
    "# maintain epoch = 100\n",
    "\n",
    "fit_model_attempt2 = nn.fit(x_train_scaled, y_train, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 - 0s - loss: 0.5725 - accuracy: 0.7259\n",
      "Attempt 2\n",
      "Loss: 0.5725187063217163, Accuracy: 0.7259474992752075\n"
     ]
    }
   ],
   "source": [
    "# Attempt 2\n",
    "# Evaluate the model\n",
    "model_loss, model_accuracy = nn.evaluate(x_test_scaled,y_test,verbose=2)\n",
    "print(\"Attempt 2\")\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy\n",
    "\n",
    "Original: 0.7225655913352966\n",
    "\n",
    "Attempt 1 (Epoch = 100):  0.7255976796150208\n",
    "    \n",
    "Attempt 2 (Epoch = 100, Double hidden layers):  0.7259474992752075"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_15 (Dense)             (None, 172)               7568      \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 86)                14878     \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 43)                3741      \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 1)                 44        \n",
      "=================================================================\n",
      "Total params: 26,231\n",
      "Trainable params: 26,231\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Attempt 3\n",
    "# Add 3rd hidden layer\n",
    "# Double number of nodes in hidden layers\n",
    "    # hidden_nodes_layer1 from 86 to 172\n",
    "    # hidden_nodes_layer2 from 43 to 86\n",
    "# maintain epoch = 100\n",
    "\n",
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "number_input_features = len(x_train_scaled[0])\n",
    "hidden_nodes_layer1 = 172\n",
    "hidden_nodes_layer2 = 86\n",
    "hidden_nodes_layer3 = 43\n",
    "\n",
    "nn = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"relu\"))\n",
    "\n",
    "# Second hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"relu\"))\n",
    "\n",
    "# Third hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer3, activation=\"relu\"))\n",
    "\n",
    "# Output layer\n",
    "nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attempt 3\n",
    "# Add 3rd hidden layer\n",
    "# Double number of nodes in hidden layers\n",
    "    # hidden_nodes_layer1 from 86 to 172\n",
    "    # hidden_nodes_layer2 from 43 to 86\n",
    "# maintain epoch = 100\n",
    "\n",
    "# Compile\n",
    "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "804/804 [==============================] - 0s 535us/step - loss: 0.5665 - accuracy: 0.7261\n",
      "Epoch 2/100\n",
      "804/804 [==============================] - 0s 542us/step - loss: 0.5545 - accuracy: 0.7322\n",
      "Epoch 3/100\n",
      "804/804 [==============================] - 0s 532us/step - loss: 0.5516 - accuracy: 0.7325\n",
      "Epoch 4/100\n",
      "804/804 [==============================] - 0s 531us/step - loss: 0.5498 - accuracy: 0.7324\n",
      "Epoch 5/100\n",
      "804/804 [==============================] - 0s 535us/step - loss: 0.5491 - accuracy: 0.7340\n",
      "Epoch 6/100\n",
      "804/804 [==============================] - 0s 528us/step - loss: 0.5478 - accuracy: 0.7353\n",
      "Epoch 7/100\n",
      "804/804 [==============================] - 0s 527us/step - loss: 0.5467 - accuracy: 0.7350\n",
      "Epoch 8/100\n",
      "804/804 [==============================] - 0s 532us/step - loss: 0.5461 - accuracy: 0.7360\n",
      "Epoch 9/100\n",
      "804/804 [==============================] - 0s 530us/step - loss: 0.5452 - accuracy: 0.7368\n",
      "Epoch 10/100\n",
      "804/804 [==============================] - 0s 531us/step - loss: 0.5450 - accuracy: 0.7355\n",
      "Epoch 11/100\n",
      "804/804 [==============================] - 0s 536us/step - loss: 0.5445 - accuracy: 0.7369\n",
      "Epoch 12/100\n",
      "804/804 [==============================] - 0s 536us/step - loss: 0.5442 - accuracy: 0.7367\n",
      "Epoch 13/100\n",
      "804/804 [==============================] - 0s 536us/step - loss: 0.5442 - accuracy: 0.7378\n",
      "Epoch 14/100\n",
      "804/804 [==============================] - 0s 532us/step - loss: 0.5437 - accuracy: 0.7367\n",
      "Epoch 15/100\n",
      "804/804 [==============================] - 0s 540us/step - loss: 0.5429 - accuracy: 0.7358\n",
      "Epoch 16/100\n",
      "804/804 [==============================] - 0s 531us/step - loss: 0.5426 - accuracy: 0.7369\n",
      "Epoch 17/100\n",
      "804/804 [==============================] - 0s 528us/step - loss: 0.5422 - accuracy: 0.7374\n",
      "Epoch 18/100\n",
      "804/804 [==============================] - 0s 537us/step - loss: 0.5420 - accuracy: 0.7369\n",
      "Epoch 19/100\n",
      "804/804 [==============================] - 0s 527us/step - loss: 0.5415 - accuracy: 0.7387\n",
      "Epoch 20/100\n",
      "804/804 [==============================] - 0s 528us/step - loss: 0.5414 - accuracy: 0.7382\n",
      "Epoch 21/100\n",
      "804/804 [==============================] - 0s 527us/step - loss: 0.5411 - accuracy: 0.7383\n",
      "Epoch 22/100\n",
      "804/804 [==============================] - 0s 533us/step - loss: 0.5407 - accuracy: 0.7388\n",
      "Epoch 23/100\n",
      "804/804 [==============================] - 0s 533us/step - loss: 0.5404 - accuracy: 0.7389\n",
      "Epoch 24/100\n",
      "804/804 [==============================] - 0s 542us/step - loss: 0.5401 - accuracy: 0.7390\n",
      "Epoch 25/100\n",
      "804/804 [==============================] - 0s 572us/step - loss: 0.5398 - accuracy: 0.7399\n",
      "Epoch 26/100\n",
      "804/804 [==============================] - 0s 536us/step - loss: 0.5396 - accuracy: 0.7395\n",
      "Epoch 27/100\n",
      "804/804 [==============================] - 0s 530us/step - loss: 0.5393 - accuracy: 0.7385\n",
      "Epoch 28/100\n",
      "804/804 [==============================] - 0s 548us/step - loss: 0.5385 - accuracy: 0.7404\n",
      "Epoch 29/100\n",
      "804/804 [==============================] - 0s 530us/step - loss: 0.5391 - accuracy: 0.7395\n",
      "Epoch 30/100\n",
      "804/804 [==============================] - 0s 530us/step - loss: 0.5389 - accuracy: 0.7397\n",
      "Epoch 31/100\n",
      "804/804 [==============================] - 0s 530us/step - loss: 0.5387 - accuracy: 0.7400\n",
      "Epoch 32/100\n",
      "804/804 [==============================] - 0s 530us/step - loss: 0.5384 - accuracy: 0.7393\n",
      "Epoch 33/100\n",
      "804/804 [==============================] - 0s 526us/step - loss: 0.5382 - accuracy: 0.7395\n",
      "Epoch 34/100\n",
      "804/804 [==============================] - 0s 528us/step - loss: 0.5378 - accuracy: 0.7396\n",
      "Epoch 35/100\n",
      "804/804 [==============================] - 0s 528us/step - loss: 0.5375 - accuracy: 0.7404\n",
      "Epoch 36/100\n",
      "804/804 [==============================] - 0s 528us/step - loss: 0.5379 - accuracy: 0.7390\n",
      "Epoch 37/100\n",
      "804/804 [==============================] - 0s 531us/step - loss: 0.5379 - accuracy: 0.7404\n",
      "Epoch 38/100\n",
      "804/804 [==============================] - 0s 535us/step - loss: 0.5377 - accuracy: 0.7397\n",
      "Epoch 39/100\n",
      "804/804 [==============================] - 0s 540us/step - loss: 0.5377 - accuracy: 0.7409\n",
      "Epoch 40/100\n",
      "804/804 [==============================] - ETA: 0s - loss: 0.5356 - accuracy: 0.74 - 0s 546us/step - loss: 0.5366 - accuracy: 0.7411\n",
      "Epoch 41/100\n",
      "804/804 [==============================] - 0s 542us/step - loss: 0.5369 - accuracy: 0.7416\n",
      "Epoch 42/100\n",
      "804/804 [==============================] - 0s 536us/step - loss: 0.5367 - accuracy: 0.7404\n",
      "Epoch 43/100\n",
      "804/804 [==============================] - 0s 536us/step - loss: 0.5368 - accuracy: 0.7403\n",
      "Epoch 44/100\n",
      "804/804 [==============================] - 0s 535us/step - loss: 0.5363 - accuracy: 0.7401\n",
      "Epoch 45/100\n",
      "804/804 [==============================] - 0s 536us/step - loss: 0.5374 - accuracy: 0.7408\n",
      "Epoch 46/100\n",
      "804/804 [==============================] - 0s 537us/step - loss: 0.5360 - accuracy: 0.7406\n",
      "Epoch 47/100\n",
      "804/804 [==============================] - 0s 535us/step - loss: 0.5361 - accuracy: 0.7399\n",
      "Epoch 48/100\n",
      "804/804 [==============================] - 0s 537us/step - loss: 0.5361 - accuracy: 0.7409\n",
      "Epoch 49/100\n",
      "804/804 [==============================] - 0s 535us/step - loss: 0.5358 - accuracy: 0.7414\n",
      "Epoch 50/100\n",
      "804/804 [==============================] - 0s 536us/step - loss: 0.5359 - accuracy: 0.7411\n",
      "Epoch 51/100\n",
      "804/804 [==============================] - 0s 538us/step - loss: 0.5357 - accuracy: 0.7413\n",
      "Epoch 52/100\n",
      "804/804 [==============================] - 0s 535us/step - loss: 0.5355 - accuracy: 0.7402\n",
      "Epoch 53/100\n",
      "804/804 [==============================] - 0s 537us/step - loss: 0.5355 - accuracy: 0.7403\n",
      "Epoch 54/100\n",
      "804/804 [==============================] - 0s 540us/step - loss: 0.5353 - accuracy: 0.7410\n",
      "Epoch 55/100\n",
      "804/804 [==============================] - 0s 543us/step - loss: 0.5355 - accuracy: 0.7406\n",
      "Epoch 56/100\n",
      "804/804 [==============================] - 0s 540us/step - loss: 0.5350 - accuracy: 0.7414\n",
      "Epoch 57/100\n",
      "804/804 [==============================] - 0s 541us/step - loss: 0.5352 - accuracy: 0.7412\n",
      "Epoch 58/100\n",
      "804/804 [==============================] - 0s 551us/step - loss: 0.5350 - accuracy: 0.7406\n",
      "Epoch 59/100\n",
      "804/804 [==============================] - 0s 552us/step - loss: 0.5345 - accuracy: 0.7413\n",
      "Epoch 60/100\n",
      "804/804 [==============================] - 0s 554us/step - loss: 0.5344 - accuracy: 0.7412\n",
      "Epoch 61/100\n",
      "804/804 [==============================] - 0s 562us/step - loss: 0.5346 - accuracy: 0.7416\n",
      "Epoch 62/100\n",
      "804/804 [==============================] - 0s 567us/step - loss: 0.5343 - accuracy: 0.7416\n",
      "Epoch 63/100\n",
      "804/804 [==============================] - 0s 543us/step - loss: 0.5348 - accuracy: 0.7420\n",
      "Epoch 64/100\n",
      "804/804 [==============================] - 0s 537us/step - loss: 0.5346 - accuracy: 0.7415\n",
      "Epoch 65/100\n",
      "804/804 [==============================] - 0s 538us/step - loss: 0.5345 - accuracy: 0.7409\n",
      "Epoch 66/100\n",
      "804/804 [==============================] - 0s 540us/step - loss: 0.5340 - accuracy: 0.7411\n",
      "Epoch 67/100\n",
      "804/804 [==============================] - 0s 537us/step - loss: 0.5343 - accuracy: 0.7418\n",
      "Epoch 68/100\n",
      "804/804 [==============================] - ETA: 0s - loss: 0.5350 - accuracy: 0.74 - 0s 538us/step - loss: 0.5341 - accuracy: 0.7409\n",
      "Epoch 69/100\n",
      "804/804 [==============================] - 0s 542us/step - loss: 0.5336 - accuracy: 0.7415\n",
      "Epoch 70/100\n",
      "804/804 [==============================] - ETA: 0s - loss: 0.5337 - accuracy: 0.74 - 0s 540us/step - loss: 0.5338 - accuracy: 0.7411\n",
      "Epoch 71/100\n",
      "804/804 [==============================] - 0s 553us/step - loss: 0.5334 - accuracy: 0.7419\n",
      "Epoch 72/100\n",
      "804/804 [==============================] - 0s 552us/step - loss: 0.5340 - accuracy: 0.7421\n",
      "Epoch 73/100\n",
      "804/804 [==============================] - 0s 550us/step - loss: 0.5341 - accuracy: 0.7416\n",
      "Epoch 74/100\n",
      "804/804 [==============================] - 0s 545us/step - loss: 0.5338 - accuracy: 0.7414\n",
      "Epoch 75/100\n",
      "804/804 [==============================] - 0s 547us/step - loss: 0.5342 - accuracy: 0.7416\n",
      "Epoch 76/100\n",
      "804/804 [==============================] - 0s 543us/step - loss: 0.5336 - accuracy: 0.7423\n",
      "Epoch 77/100\n",
      "804/804 [==============================] - 0s 543us/step - loss: 0.5335 - accuracy: 0.7422\n",
      "Epoch 78/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "804/804 [==============================] - 0s 546us/step - loss: 0.5347 - accuracy: 0.7416\n",
      "Epoch 79/100\n",
      "804/804 [==============================] - 0s 547us/step - loss: 0.5341 - accuracy: 0.7421\n",
      "Epoch 80/100\n",
      "804/804 [==============================] - 0s 542us/step - loss: 0.5329 - accuracy: 0.7418\n",
      "Epoch 81/100\n",
      "804/804 [==============================] - 0s 542us/step - loss: 0.5331 - accuracy: 0.7411\n",
      "Epoch 82/100\n",
      "804/804 [==============================] - 0s 548us/step - loss: 0.5329 - accuracy: 0.7416\n",
      "Epoch 83/100\n",
      "804/804 [==============================] - 0s 545us/step - loss: 0.5331 - accuracy: 0.7417\n",
      "Epoch 84/100\n",
      "804/804 [==============================] - ETA: 0s - loss: 0.5336 - accuracy: 0.74 - 0s 537us/step - loss: 0.5329 - accuracy: 0.7420\n",
      "Epoch 85/100\n",
      "804/804 [==============================] - 0s 542us/step - loss: 0.5336 - accuracy: 0.7423\n",
      "Epoch 86/100\n",
      "804/804 [==============================] - 0s 546us/step - loss: 0.5329 - accuracy: 0.7418\n",
      "Epoch 87/100\n",
      "804/804 [==============================] - 0s 546us/step - loss: 0.5327 - accuracy: 0.7417\n",
      "Epoch 88/100\n",
      "804/804 [==============================] - 0s 540us/step - loss: 0.5330 - accuracy: 0.7417\n",
      "Epoch 89/100\n",
      "804/804 [==============================] - 0s 545us/step - loss: 0.5328 - accuracy: 0.7419\n",
      "Epoch 90/100\n",
      "804/804 [==============================] - 0s 542us/step - loss: 0.5331 - accuracy: 0.7424\n",
      "Epoch 91/100\n",
      "804/804 [==============================] - 0s 543us/step - loss: 0.5334 - accuracy: 0.7412\n",
      "Epoch 92/100\n",
      "804/804 [==============================] - 0s 545us/step - loss: 0.5329 - accuracy: 0.7421\n",
      "Epoch 93/100\n",
      "804/804 [==============================] - 0s 541us/step - loss: 0.5323 - accuracy: 0.7425\n",
      "Epoch 94/100\n",
      "804/804 [==============================] - 0s 546us/step - loss: 0.5324 - accuracy: 0.7416\n",
      "Epoch 95/100\n",
      "804/804 [==============================] - 0s 545us/step - loss: 0.5322 - accuracy: 0.7435\n",
      "Epoch 96/100\n",
      "804/804 [==============================] - 0s 543us/step - loss: 0.5324 - accuracy: 0.7420\n",
      "Epoch 97/100\n",
      "804/804 [==============================] - 0s 550us/step - loss: 0.5322 - accuracy: 0.7413\n",
      "Epoch 98/100\n",
      "804/804 [==============================] - 0s 578us/step - loss: 0.5324 - accuracy: 0.7424\n",
      "Epoch 99/100\n",
      "804/804 [==============================] - 0s 548us/step - loss: 0.5322 - accuracy: 0.7420\n",
      "Epoch 100/100\n",
      "804/804 [==============================] - 0s 540us/step - loss: 0.5320 - accuracy: 0.7429\n"
     ]
    }
   ],
   "source": [
    "# Attempt 3\n",
    "# Add 3rd hidden layer\n",
    "# Double number of nodes in hidden layers\n",
    "    # hidden_nodes_layer1 from 86 to 172\n",
    "    # hidden_nodes_layer2 from 43 to 86\n",
    "# maintain epoch = 100\n",
    "\n",
    "fit_model_attempt3 = nn.fit(x_train_scaled, y_train, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 - 0s - loss: 0.5920 - accuracy: 0.7247\n",
      "Attempt 2\n",
      "Loss: 0.5920268297195435, Accuracy: 0.7246647477149963\n"
     ]
    }
   ],
   "source": [
    "# Attempt 3\n",
    "# Add 3rd hidden layer\n",
    "# Double number of nodes in hidden layers\n",
    "    # hidden_nodes_layer1 from 86 to 172\n",
    "    # hidden_nodes_layer2 from 43 to 86\n",
    "# maintain epoch = 100\n",
    "\n",
    "# Evaluate the model\n",
    "model_loss, model_accuracy = nn.evaluate(x_test_scaled,y_test,verbose=2)\n",
    "print(\"Attempt 3\")\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy\n",
    "\n",
    "Original: 0.7225655913352966\n",
    "\n",
    "Attempt 1 \n",
    "    (Epoch = 100):  \n",
    "        0.7255976796150208\n",
    "    \n",
    "Attempt 2 \n",
    "    (Epoch = 100, Double hidden layers):  \n",
    "        0.7259474992752075\n",
    "    \n",
    "Attempt 3 \n",
    "    (Epoch = 100, Double hidden layers, Add 3rd hidden layers):\n",
    "        0.7246647477149963"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_19 (Dense)             (None, 172)               7568      \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 86)                14878     \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 43)                3741      \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 1)                 44        \n",
      "=================================================================\n",
      "Total params: 26,231\n",
      "Trainable params: 26,231\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Attempt 4\n",
    "# Change activation function from relu to swish\n",
    "# Add 3rd hidden layer\n",
    "# Double number of nodes in hidden layers\n",
    "    # hidden_nodes_layer1 from 86 to 172\n",
    "    # hidden_nodes_layer2 from 43 to 86\n",
    "# maintain epoch = 100\n",
    "\n",
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "number_input_features = len(x_train_scaled[0])\n",
    "hidden_nodes_layer1 = 172\n",
    "hidden_nodes_layer2 = 86\n",
    "hidden_nodes_layer3 = 43\n",
    "\n",
    "nn = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer1, input_dim=number_input_features, activation=\"swish\"))\n",
    "\n",
    "# Second hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer2, activation=\"swish\"))\n",
    "\n",
    "# Third hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_nodes_layer3, activation=\"swish\"))\n",
    "\n",
    "# Output layer\n",
    "nn.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attempt 4\n",
    "# Change activation function from relu to swish\n",
    "# Add 3rd hidden layer\n",
    "# Double number of nodes in hidden layers\n",
    "    # hidden_nodes_layer1 from 86 to 172\n",
    "    # hidden_nodes_layer2 from 43 to 86\n",
    "# maintain epoch = 100\n",
    "\n",
    "# Compile\n",
    "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "804/804 [==============================] - 0s 561us/step - loss: 0.5686 - accuracy: 0.7230\n",
      "Epoch 2/100\n",
      "804/804 [==============================] - 0s 556us/step - loss: 0.5550 - accuracy: 0.7313\n",
      "Epoch 3/100\n",
      "804/804 [==============================] - 0s 558us/step - loss: 0.5523 - accuracy: 0.7308\n",
      "Epoch 4/100\n",
      "804/804 [==============================] - 0s 552us/step - loss: 0.5503 - accuracy: 0.7328\n",
      "Epoch 5/100\n",
      "804/804 [==============================] - 0s 553us/step - loss: 0.5494 - accuracy: 0.7339\n",
      "Epoch 6/100\n",
      "804/804 [==============================] - 0s 554us/step - loss: 0.5485 - accuracy: 0.7341\n",
      "Epoch 7/100\n",
      "804/804 [==============================] - 0s 556us/step - loss: 0.5477 - accuracy: 0.7337\n",
      "Epoch 8/100\n",
      "804/804 [==============================] - 0s 554us/step - loss: 0.5470 - accuracy: 0.7343\n",
      "Epoch 9/100\n",
      "804/804 [==============================] - 0s 562us/step - loss: 0.5459 - accuracy: 0.7357\n",
      "Epoch 10/100\n",
      "804/804 [==============================] - 0s 554us/step - loss: 0.5454 - accuracy: 0.7358\n",
      "Epoch 11/100\n",
      "804/804 [==============================] - 0s 556us/step - loss: 0.5451 - accuracy: 0.7356\n",
      "Epoch 12/100\n",
      "804/804 [==============================] - 0s 551us/step - loss: 0.5447 - accuracy: 0.7352\n",
      "Epoch 13/100\n",
      "804/804 [==============================] - 0s 551us/step - loss: 0.5439 - accuracy: 0.7356\n",
      "Epoch 14/100\n",
      "804/804 [==============================] - 0s 559us/step - loss: 0.5438 - accuracy: 0.7369\n",
      "Epoch 15/100\n",
      "804/804 [==============================] - 0s 584us/step - loss: 0.5437 - accuracy: 0.7364\n",
      "Epoch 16/100\n",
      "804/804 [==============================] - 0s 556us/step - loss: 0.5423 - accuracy: 0.7376\n",
      "Epoch 17/100\n",
      "804/804 [==============================] - 0s 559us/step - loss: 0.5425 - accuracy: 0.7364\n",
      "Epoch 18/100\n",
      "804/804 [==============================] - 0s 561us/step - loss: 0.5423 - accuracy: 0.7374\n",
      "Epoch 19/100\n",
      "804/804 [==============================] - 0s 551us/step - loss: 0.5418 - accuracy: 0.7381\n",
      "Epoch 20/100\n",
      "804/804 [==============================] - 0s 552us/step - loss: 0.5414 - accuracy: 0.7375\n",
      "Epoch 21/100\n",
      "804/804 [==============================] - 0s 552us/step - loss: 0.5409 - accuracy: 0.7395\n",
      "Epoch 22/100\n",
      "804/804 [==============================] - 0s 556us/step - loss: 0.5412 - accuracy: 0.7374\n",
      "Epoch 23/100\n",
      "804/804 [==============================] - 0s 557us/step - loss: 0.5402 - accuracy: 0.7381\n",
      "Epoch 24/100\n",
      "804/804 [==============================] - 0s 554us/step - loss: 0.5404 - accuracy: 0.7377\n",
      "Epoch 25/100\n",
      "804/804 [==============================] - 0s 562us/step - loss: 0.5399 - accuracy: 0.7388\n",
      "Epoch 26/100\n",
      "804/804 [==============================] - 0s 553us/step - loss: 0.5396 - accuracy: 0.7392\n",
      "Epoch 27/100\n",
      "804/804 [==============================] - 0s 568us/step - loss: 0.5392 - accuracy: 0.7385\n",
      "Epoch 28/100\n",
      "804/804 [==============================] - 0s 554us/step - loss: 0.5394 - accuracy: 0.7390\n",
      "Epoch 29/100\n",
      "804/804 [==============================] - 0s 547us/step - loss: 0.5392 - accuracy: 0.7388\n",
      "Epoch 30/100\n",
      "804/804 [==============================] - 0s 548us/step - loss: 0.5387 - accuracy: 0.7379\n",
      "Epoch 31/100\n",
      "804/804 [==============================] - 0s 552us/step - loss: 0.5386 - accuracy: 0.7392\n",
      "Epoch 32/100\n",
      "804/804 [==============================] - 0s 561us/step - loss: 0.5384 - accuracy: 0.7393\n",
      "Epoch 33/100\n",
      "804/804 [==============================] - 0s 553us/step - loss: 0.5378 - accuracy: 0.7392\n",
      "Epoch 34/100\n",
      "804/804 [==============================] - 0s 552us/step - loss: 0.5381 - accuracy: 0.7391\n",
      "Epoch 35/100\n",
      "804/804 [==============================] - 0s 550us/step - loss: 0.5377 - accuracy: 0.7385\n",
      "Epoch 36/100\n",
      "804/804 [==============================] - 0s 556us/step - loss: 0.5373 - accuracy: 0.7409\n",
      "Epoch 37/100\n",
      "804/804 [==============================] - 0s 562us/step - loss: 0.5374 - accuracy: 0.7395\n",
      "Epoch 38/100\n",
      "804/804 [==============================] - 0s 566us/step - loss: 0.5369 - accuracy: 0.7393\n",
      "Epoch 39/100\n",
      "804/804 [==============================] - 0s 554us/step - loss: 0.5373 - accuracy: 0.7389\n",
      "Epoch 40/100\n",
      "804/804 [==============================] - 0s 563us/step - loss: 0.5367 - accuracy: 0.7409\n",
      "Epoch 41/100\n",
      "804/804 [==============================] - 0s 561us/step - loss: 0.5369 - accuracy: 0.7393\n",
      "Epoch 42/100\n",
      "804/804 [==============================] - 0s 573us/step - loss: 0.5363 - accuracy: 0.7393\n",
      "Epoch 43/100\n",
      "804/804 [==============================] - 0s 558us/step - loss: 0.5362 - accuracy: 0.7406\n",
      "Epoch 44/100\n",
      "804/804 [==============================] - 0s 559us/step - loss: 0.5363 - accuracy: 0.7401\n",
      "Epoch 45/100\n",
      "804/804 [==============================] - 0s 568us/step - loss: 0.5364 - accuracy: 0.7402\n",
      "Epoch 46/100\n",
      "804/804 [==============================] - 0s 566us/step - loss: 0.5351 - accuracy: 0.7404\n",
      "Epoch 47/100\n",
      "804/804 [==============================] - 0s 558us/step - loss: 0.5358 - accuracy: 0.7402\n",
      "Epoch 48/100\n",
      "804/804 [==============================] - 0s 559us/step - loss: 0.5357 - accuracy: 0.7406\n",
      "Epoch 49/100\n",
      "804/804 [==============================] - 0s 563us/step - loss: 0.5351 - accuracy: 0.7404\n",
      "Epoch 50/100\n",
      "804/804 [==============================] - 0s 595us/step - loss: 0.5355 - accuracy: 0.7405\n",
      "Epoch 51/100\n",
      "804/804 [==============================] - 0s 597us/step - loss: 0.5355 - accuracy: 0.7414\n",
      "Epoch 52/100\n",
      "804/804 [==============================] - 0s 568us/step - loss: 0.5358 - accuracy: 0.7412\n",
      "Epoch 53/100\n",
      "804/804 [==============================] - 0s 566us/step - loss: 0.5347 - accuracy: 0.7411\n",
      "Epoch 54/100\n",
      "804/804 [==============================] - 0s 567us/step - loss: 0.5349 - accuracy: 0.7407\n",
      "Epoch 55/100\n",
      "804/804 [==============================] - 0s 572us/step - loss: 0.5348 - accuracy: 0.7409\n",
      "Epoch 56/100\n",
      "804/804 [==============================] - 0s 572us/step - loss: 0.5347 - accuracy: 0.7412\n",
      "Epoch 57/100\n",
      "804/804 [==============================] - 0s 572us/step - loss: 0.5345 - accuracy: 0.7413\n",
      "Epoch 58/100\n",
      "804/804 [==============================] - 0s 563us/step - loss: 0.5344 - accuracy: 0.7411\n",
      "Epoch 59/100\n",
      "804/804 [==============================] - 0s 576us/step - loss: 0.5344 - accuracy: 0.7412\n",
      "Epoch 60/100\n",
      "804/804 [==============================] - 0s 567us/step - loss: 0.5347 - accuracy: 0.7411\n",
      "Epoch 61/100\n",
      "804/804 [==============================] - 0s 576us/step - loss: 0.5338 - accuracy: 0.7404\n",
      "Epoch 62/100\n",
      "804/804 [==============================] - 0s 567us/step - loss: 0.5344 - accuracy: 0.7406\n",
      "Epoch 63/100\n",
      "804/804 [==============================] - 0s 561us/step - loss: 0.5342 - accuracy: 0.7417\n",
      "Epoch 64/100\n",
      "804/804 [==============================] - 0s 562us/step - loss: 0.5336 - accuracy: 0.7411\n",
      "Epoch 65/100\n",
      "804/804 [==============================] - 0s 583us/step - loss: 0.5343 - accuracy: 0.7409\n",
      "Epoch 66/100\n",
      "804/804 [==============================] - 0s 566us/step - loss: 0.5334 - accuracy: 0.7411\n",
      "Epoch 67/100\n",
      "804/804 [==============================] - 0s 571us/step - loss: 0.5338 - accuracy: 0.7413\n",
      "Epoch 68/100\n",
      "804/804 [==============================] - 0s 567us/step - loss: 0.5339 - accuracy: 0.7418\n",
      "Epoch 69/100\n",
      "804/804 [==============================] - 0s 573us/step - loss: 0.5333 - accuracy: 0.7416\n",
      "Epoch 70/100\n",
      "804/804 [==============================] - 0s 572us/step - loss: 0.5335 - accuracy: 0.7416\n",
      "Epoch 71/100\n",
      "804/804 [==============================] - 0s 568us/step - loss: 0.5336 - accuracy: 0.7404\n",
      "Epoch 72/100\n",
      "804/804 [==============================] - 0s 572us/step - loss: 0.5337 - accuracy: 0.7416\n",
      "Epoch 73/100\n",
      "804/804 [==============================] - 0s 577us/step - loss: 0.5331 - accuracy: 0.7414\n",
      "Epoch 74/100\n",
      "804/804 [==============================] - 0s 568us/step - loss: 0.5334 - accuracy: 0.7417\n",
      "Epoch 75/100\n",
      "804/804 [==============================] - 0s 576us/step - loss: 0.5330 - accuracy: 0.7408\n",
      "Epoch 76/100\n",
      "804/804 [==============================] - 0s 567us/step - loss: 0.5333 - accuracy: 0.7413\n",
      "Epoch 77/100\n",
      "804/804 [==============================] - 0s 574us/step - loss: 0.5331 - accuracy: 0.7416\n",
      "Epoch 78/100\n",
      "804/804 [==============================] - 0s 571us/step - loss: 0.5326 - accuracy: 0.7416\n",
      "Epoch 79/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "804/804 [==============================] - 0s 573us/step - loss: 0.5333 - accuracy: 0.7408\n",
      "Epoch 80/100\n",
      "804/804 [==============================] - 0s 571us/step - loss: 0.5327 - accuracy: 0.7416\n",
      "Epoch 81/100\n",
      "804/804 [==============================] - 0s 573us/step - loss: 0.5329 - accuracy: 0.7417\n",
      "Epoch 82/100\n",
      "804/804 [==============================] - 0s 576us/step - loss: 0.5326 - accuracy: 0.7418\n",
      "Epoch 83/100\n",
      "804/804 [==============================] - 0s 573us/step - loss: 0.5340 - accuracy: 0.7417\n",
      "Epoch 84/100\n",
      "804/804 [==============================] - 0s 576us/step - loss: 0.5326 - accuracy: 0.7419\n",
      "Epoch 85/100\n",
      "804/804 [==============================] - 0s 603us/step - loss: 0.5324 - accuracy: 0.7428\n",
      "Epoch 86/100\n",
      "804/804 [==============================] - 0s 577us/step - loss: 0.5328 - accuracy: 0.7416\n",
      "Epoch 87/100\n",
      "804/804 [==============================] - 0s 567us/step - loss: 0.5327 - accuracy: 0.7417\n",
      "Epoch 88/100\n",
      "804/804 [==============================] - 0s 567us/step - loss: 0.5323 - accuracy: 0.7412\n",
      "Epoch 89/100\n",
      "804/804 [==============================] - 0s 572us/step - loss: 0.5327 - accuracy: 0.7418\n",
      "Epoch 90/100\n",
      "804/804 [==============================] - 0s 566us/step - loss: 0.5324 - accuracy: 0.7421\n",
      "Epoch 91/100\n",
      "804/804 [==============================] - 0s 568us/step - loss: 0.5318 - accuracy: 0.7416\n",
      "Epoch 92/100\n",
      "804/804 [==============================] - 0s 566us/step - loss: 0.5327 - accuracy: 0.7417\n",
      "Epoch 93/100\n",
      "804/804 [==============================] - 0s 578us/step - loss: 0.5325 - accuracy: 0.7421\n",
      "Epoch 94/100\n",
      "804/804 [==============================] - 0s 577us/step - loss: 0.5323 - accuracy: 0.7422\n",
      "Epoch 95/100\n",
      "804/804 [==============================] - 0s 598us/step - loss: 0.5316 - accuracy: 0.7420\n",
      "Epoch 96/100\n",
      "804/804 [==============================] - 0s 566us/step - loss: 0.5325 - accuracy: 0.7419\n",
      "Epoch 97/100\n",
      "804/804 [==============================] - 0s 603us/step - loss: 0.5325 - accuracy: 0.7419\n",
      "Epoch 98/100\n",
      "804/804 [==============================] - 0s 581us/step - loss: 0.5318 - accuracy: 0.7418\n",
      "Epoch 99/100\n",
      "804/804 [==============================] - 0s 573us/step - loss: 0.5327 - accuracy: 0.7422\n",
      "Epoch 100/100\n",
      "804/804 [==============================] - 0s 572us/step - loss: 0.5320 - accuracy: 0.7418\n"
     ]
    }
   ],
   "source": [
    "# Attempt 4\n",
    "# Change activation function from relu to swish\n",
    "# Add 3rd hidden layer\n",
    "# Double number of nodes in hidden layers\n",
    "    # hidden_nodes_layer1 from 86 to 172\n",
    "    # hidden_nodes_layer2 from 43 to 86\n",
    "# maintain epoch = 100\n",
    "\n",
    "fit_model_attempt4 = nn.fit(x_train_scaled, y_train, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 - 0s - loss: 0.5773 - accuracy: 0.7257\n",
      "Attempt 4\n",
      "Loss: 0.5773299932479858, Accuracy: 0.7257142663002014\n"
     ]
    }
   ],
   "source": [
    "# Attempt 4\n",
    "# Change activation function from relu to swish\n",
    "# Add 3rd hidden layer\n",
    "# Double number of nodes in hidden layers\n",
    "    # hidden_nodes_layer1 from 86 to 172\n",
    "    # hidden_nodes_layer2 from 43 to 86\n",
    "# maintain epoch = 100\n",
    "\n",
    "# Evaluate the model\n",
    "model_loss, model_accuracy = nn.evaluate(x_test_scaled,y_test,verbose=2)\n",
    "print(\"Attempt 4\")\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy\n",
    "\n",
    "Original: 0.7225655913352966\n",
    "\n",
    "Attempt 1 \n",
    "    * (Epoch = 100):  \n",
    "        * 0.7255976796150208\n",
    "    \n",
    "Attempt 2 \n",
    "    * (Epoch = 100, Double hidden layers):  \n",
    "        * 0.7259474992752075\n",
    "    \n",
    "Attempt 3 \n",
    "    * (Epoch = 100, Double hidden layers, Add 3rd hidden layers):\n",
    "        * 0.7246647477149963\n",
    "        \n",
    "Attempt 4\n",
    "    *  (Epoch = 100, Double hidden layers, Add 3rd hidden layers, Change activation from relu to swish):\n",
    "        * 0.7257142663002014"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the checkpoint path and filenames\n",
    "os.makedirs(\"modified_checkpoints/\",exist_ok=True)\n",
    "checkpoint_path = \"modified_checkpoints/final_weights.{epoch:02d}.hdf5\"\n",
    "\n",
    "# Create a callback that saves the model's weights every 5 epochs\n",
    "cp_callback = ModelCheckpoint(\n",
    "    filepath=checkpoint_path,\n",
    "    verbose=1,\n",
    "    save_weights_only=True,\n",
    "    save_freq=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "804/804 [==============================] - 0s 572us/step - loss: 0.5318 - accuracy: 0.7421\n",
      "Epoch 2/100\n",
      "181/804 [=====>........................] - ETA: 0s - loss: 0.5294 - accuracy: 0.7405\n",
      "Epoch 00002: saving model to modified_checkpoints\\final_weights.02.hdf5\n",
      "804/804 [==============================] - 0s 574us/step - loss: 0.5317 - accuracy: 0.7423\n",
      "Epoch 3/100\n",
      "363/804 [============>.................] - ETA: 0s - loss: 0.5296 - accuracy: 0.7429\n",
      "Epoch 00003: saving model to modified_checkpoints\\final_weights.03.hdf5\n",
      "804/804 [==============================] - 0s 614us/step - loss: 0.5318 - accuracy: 0.7420\n",
      "Epoch 4/100\n",
      "531/804 [==================>...........] - ETA: 0s - loss: 0.5300 - accuracy: 0.7432\n",
      "Epoch 00004: saving model to modified_checkpoints\\final_weights.04.hdf5\n",
      "804/804 [==============================] - 0s 587us/step - loss: 0.5315 - accuracy: 0.7418\n",
      "Epoch 5/100\n",
      "720/804 [=========================>....] - ETA: 0s - loss: 0.5342 - accuracy: 0.7421\n",
      "Epoch 00005: saving model to modified_checkpoints\\final_weights.05.hdf5\n",
      "804/804 [==============================] - 0s 576us/step - loss: 0.5339 - accuracy: 0.7418\n",
      "Epoch 6/100\n",
      "804/804 [==============================] - 0s 562us/step - loss: 0.5316 - accuracy: 0.7422\n",
      "Epoch 7/100\n",
      " 91/804 [==>...........................] - ETA: 0s - loss: 0.5430 - accuracy: 0.7363\n",
      "Epoch 00007: saving model to modified_checkpoints\\final_weights.07.hdf5\n",
      "804/804 [==============================] - 0s 568us/step - loss: 0.5314 - accuracy: 0.7422\n",
      "Epoch 8/100\n",
      "304/804 [==========>...................] - ETA: 0s - loss: 0.5308 - accuracy: 0.7448\n",
      "Epoch 00008: saving model to modified_checkpoints\\final_weights.08.hdf5\n",
      "804/804 [==============================] - 0s 614us/step - loss: 0.5320 - accuracy: 0.7420\n",
      "Epoch 9/100\n",
      "525/804 [==================>...........] - ETA: 0s - loss: 0.5345 - accuracy: 0.7391\n",
      "Epoch 00009: saving model to modified_checkpoints\\final_weights.09.hdf5\n",
      "804/804 [==============================] - 0s 588us/step - loss: 0.5315 - accuracy: 0.7421\n",
      "Epoch 10/100\n",
      "726/804 [==========================>...] - ETA: 0s - loss: 0.5306 - accuracy: 0.7429\n",
      "Epoch 00010: saving model to modified_checkpoints\\final_weights.10.hdf5\n",
      "804/804 [==============================] - 0s 571us/step - loss: 0.5315 - accuracy: 0.7420\n",
      "Epoch 11/100\n",
      "804/804 [==============================] - 0s 574us/step - loss: 0.5317 - accuracy: 0.7421\n",
      "Epoch 12/100\n",
      " 91/804 [==>...........................] - ETA: 0s - loss: 0.5462 - accuracy: 0.7263\n",
      "Epoch 00012: saving model to modified_checkpoints\\final_weights.12.hdf5\n",
      "804/804 [==============================] - 1s 624us/step - loss: 0.5317 - accuracy: 0.7425\n",
      "Epoch 13/100\n",
      "270/804 [=========>....................] - ETA: 0s - loss: 0.5230 - accuracy: 0.7490\n",
      "Epoch 00013: saving model to modified_checkpoints\\final_weights.13.hdf5\n",
      "804/804 [==============================] - 0s 577us/step - loss: 0.5314 - accuracy: 0.7421\n",
      "Epoch 14/100\n",
      "539/804 [===================>..........] - ETA: 0s - loss: 0.5322 - accuracy: 0.7399\n",
      "Epoch 00014: saving model to modified_checkpoints\\final_weights.14.hdf5\n",
      "804/804 [==============================] - 0s 576us/step - loss: 0.5312 - accuracy: 0.7425\n",
      "Epoch 15/100\n",
      "716/804 [=========================>....] - ETA: 0s - loss: 0.5298 - accuracy: 0.7438\n",
      "Epoch 00015: saving model to modified_checkpoints\\final_weights.15.hdf5\n",
      "804/804 [==============================] - 0s 577us/step - loss: 0.5310 - accuracy: 0.7423\n",
      "Epoch 16/100\n",
      "804/804 [==============================] - 0s 619us/step - loss: 0.5310 - accuracy: 0.7425\n",
      "Epoch 17/100\n",
      " 91/804 [==>...........................] - ETA: 0s - loss: 0.5304 - accuracy: 0.7435\n",
      "Epoch 00017: saving model to modified_checkpoints\\final_weights.17.hdf5\n",
      "804/804 [==============================] - 0s 581us/step - loss: 0.5317 - accuracy: 0.7424\n",
      "Epoch 18/100\n",
      "297/804 [==========>...................] - ETA: 0s - loss: 0.5309 - accuracy: 0.7411\n",
      "Epoch 00018: saving model to modified_checkpoints\\final_weights.18.hdf5\n",
      "804/804 [==============================] - 1s 626us/step - loss: 0.5320 - accuracy: 0.7420\n",
      "Epoch 19/100\n",
      "449/804 [===============>..............] - ETA: 0s - loss: 0.5265 - accuracy: 0.7430\n",
      "Epoch 00019: saving model to modified_checkpoints\\final_weights.19.hdf5\n",
      "804/804 [==============================] - 0s 581us/step - loss: 0.5322 - accuracy: 0.7413\n",
      "Epoch 20/100\n",
      "722/804 [=========================>....] - ETA: 0s - loss: 0.5309 - accuracy: 0.7431\n",
      "Epoch 00020: saving model to modified_checkpoints\\final_weights.20.hdf5\n",
      "804/804 [==============================] - 0s 573us/step - loss: 0.5311 - accuracy: 0.7424\n",
      "Epoch 21/100\n",
      "804/804 [==============================] - 0s 574us/step - loss: 0.5307 - accuracy: 0.7418\n",
      "Epoch 22/100\n",
      " 91/804 [==>...........................] - ETA: 0s - loss: 0.5367 - accuracy: 0.7418\n",
      "Epoch 00022: saving model to modified_checkpoints\\final_weights.22.hdf5\n",
      "804/804 [==============================] - 0s 610us/step - loss: 0.5309 - accuracy: 0.7425\n",
      "Epoch 23/100\n",
      "270/804 [=========>....................] - ETA: 0s - loss: 0.5310 - accuracy: 0.7421\n",
      "Epoch 00023: saving model to modified_checkpoints\\final_weights.23.hdf5\n",
      "804/804 [==============================] - 0s 585us/step - loss: 0.5314 - accuracy: 0.7423\n",
      "Epoch 24/100\n",
      "503/804 [=================>............] - ETA: 0s - loss: 0.5290 - accuracy: 0.7450\n",
      "Epoch 00024: saving model to modified_checkpoints\\final_weights.24.hdf5\n",
      "804/804 [==============================] - 0s 619us/step - loss: 0.5314 - accuracy: 0.7427\n",
      "Epoch 25/100\n",
      "696/804 [========================>.....] - ETA: 0s - loss: 0.5314 - accuracy: 0.7417\n",
      "Epoch 00025: saving model to modified_checkpoints\\final_weights.25.hdf5\n",
      "804/804 [==============================] - 0s 598us/step - loss: 0.5313 - accuracy: 0.7418\n",
      "Epoch 26/100\n",
      "804/804 [==============================] - 1s 675us/step - loss: 0.5313 - accuracy: 0.7420\n",
      "Epoch 27/100\n",
      " 90/804 [==>...........................] - ETA: 0s - loss: 0.5130 - accuracy: 0.7580\n",
      "Epoch 00027: saving model to modified_checkpoints\\final_weights.27.hdf5\n",
      "804/804 [==============================] - 0s 573us/step - loss: 0.5309 - accuracy: 0.7425\n",
      "Epoch 28/100\n",
      "268/804 [=========>....................] - ETA: 0s - loss: 0.5277 - accuracy: 0.7444\n",
      "Epoch 00028: saving model to modified_checkpoints\\final_weights.28.hdf5\n",
      "804/804 [==============================] - 0s 577us/step - loss: 0.5311 - accuracy: 0.7425\n",
      "Epoch 29/100\n",
      "452/804 [===============>..............] - ETA: 0s - loss: 0.5333 - accuracy: 0.7371\n",
      "Epoch 00029: saving model to modified_checkpoints\\final_weights.29.hdf5\n",
      "804/804 [==============================] - 0s 573us/step - loss: 0.5312 - accuracy: 0.7423\n",
      "Epoch 30/100\n",
      "660/804 [=======================>......] - ETA: 0s - loss: 0.5311 - accuracy: 0.7424\n",
      "Epoch 00030: saving model to modified_checkpoints\\final_weights.30.hdf5\n",
      "804/804 [==============================] - 0s 619us/step - loss: 0.5312 - accuracy: 0.7424\n",
      "Epoch 31/100\n",
      "804/804 [==============================] - 0s 567us/step - loss: 0.5309 - accuracy: 0.7425\n",
      "Epoch 32/100\n",
      "  1/804 [..............................] - ETA: 0s - loss: 0.4668 - accuracy: 0.7500\n",
      "Epoch 00032: saving model to modified_checkpoints\\final_weights.32.hdf5\n",
      "804/804 [==============================] - 0s 585us/step - loss: 0.5312 - accuracy: 0.7418\n",
      "Epoch 33/100\n",
      "270/804 [=========>....................] - ETA: 0s - loss: 0.5341 - accuracy: 0.7409\n",
      "Epoch 00033: saving model to modified_checkpoints\\final_weights.33.hdf5\n",
      "804/804 [==============================] - 0s 581us/step - loss: 0.5307 - accuracy: 0.7428\n",
      "Epoch 34/100\n",
      "393/804 [=============>................] - ETA: 0s - loss: 0.5287 - accuracy: 0.7435\n",
      "Epoch 00034: saving model to modified_checkpoints\\final_weights.34.hdf5\n",
      "804/804 [==============================] - 1s 628us/step - loss: 0.5323 - accuracy: 0.7425\n",
      "Epoch 35/100\n",
      "622/804 [======================>.......] - ETA: 0s - loss: 0.5319 - accuracy: 0.7427\n",
      "Epoch 00035: saving model to modified_checkpoints\\final_weights.35.hdf5\n",
      "804/804 [==============================] - 0s 584us/step - loss: 0.5320 - accuracy: 0.7424\n",
      "Epoch 36/100\n",
      "804/804 [==============================] - 0s 585us/step - loss: 0.5309 - accuracy: 0.7420\n",
      "Epoch 37/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1/804 [..............................] - ETA: 0s - loss: 0.4379 - accuracy: 0.7812\n",
      "Epoch 00037: saving model to modified_checkpoints\\final_weights.37.hdf5\n",
      "804/804 [==============================] - 0s 582us/step - loss: 0.5313 - accuracy: 0.7433\n",
      "Epoch 38/100\n",
      "209/804 [======>.......................] - ETA: 0s - loss: 0.5278 - accuracy: 0.7478\n",
      "Epoch 00038: saving model to modified_checkpoints\\final_weights.38.hdf5\n",
      "804/804 [==============================] - 1s 636us/step - loss: 0.5309 - accuracy: 0.7423\n",
      "Epoch 39/100\n",
      "358/804 [============>.................] - ETA: 0s - loss: 0.5296 - accuracy: 0.7431\n",
      "Epoch 00039: saving model to modified_checkpoints\\final_weights.39.hdf5\n",
      "804/804 [==============================] - 0s 578us/step - loss: 0.5307 - accuracy: 0.7422\n",
      "Epoch 40/100\n",
      "613/804 [=====================>........] - ETA: 0s - loss: 0.5310 - accuracy: 0.7427\n",
      "Epoch 00040: saving model to modified_checkpoints\\final_weights.40.hdf5\n",
      "804/804 [==============================] - 0s 593us/step - loss: 0.5305 - accuracy: 0.7426\n",
      "Epoch 41/100\n",
      "804/804 [==============================] - 0s 569us/step - loss: 0.5303 - accuracy: 0.7430\n",
      "Epoch 42/100\n",
      "  1/804 [..............................] - ETA: 0s - loss: 0.4787 - accuracy: 0.8125\n",
      "Epoch 00042: saving model to modified_checkpoints\\final_weights.42.hdf5\n",
      "804/804 [==============================] - 0s 620us/step - loss: 0.5315 - accuracy: 0.7423\n",
      "Epoch 43/100\n",
      "180/804 [=====>........................] - ETA: 0s - loss: 0.5245 - accuracy: 0.7490\n",
      "Epoch 00043: saving model to modified_checkpoints\\final_weights.43.hdf5\n",
      "804/804 [==============================] - 0s 576us/step - loss: 0.5324 - accuracy: 0.7424\n",
      "Epoch 44/100\n",
      "349/804 [============>.................] - ETA: 0s - loss: 0.5295 - accuracy: 0.7419\n",
      "Epoch 00044: saving model to modified_checkpoints\\final_weights.44.hdf5\n",
      "804/804 [==============================] - 0s 592us/step - loss: 0.5309 - accuracy: 0.7423\n",
      "Epoch 45/100\n",
      "540/804 [===================>..........] - ETA: 0s - loss: 0.5344 - accuracy: 0.7400\n",
      "Epoch 00045: saving model to modified_checkpoints\\final_weights.45.hdf5\n",
      "804/804 [==============================] - 0s 610us/step - loss: 0.5305 - accuracy: 0.7425\n",
      "Epoch 46/100\n",
      "804/804 [==============================] - 0s 583us/step - loss: 0.5307 - accuracy: 0.7423\n",
      "Epoch 47/100\n",
      "  1/804 [..............................] - ETA: 0s - loss: 0.4903 - accuracy: 0.7812\n",
      "Epoch 00047: saving model to modified_checkpoints\\final_weights.47.hdf5\n",
      "804/804 [==============================] - 0s 579us/step - loss: 0.5305 - accuracy: 0.7424\n",
      "Epoch 48/100\n",
      "180/804 [=====>........................] - ETA: 0s - loss: 0.5232 - accuracy: 0.7500\n",
      "Epoch 00048: saving model to modified_checkpoints\\final_weights.48.hdf5\n",
      "804/804 [==============================] - 0s 574us/step - loss: 0.5303 - accuracy: 0.7427\n",
      "Epoch 49/100\n",
      "360/804 [============>.................] - ETA: 0s - loss: 0.5314 - accuracy: 0.7395\n",
      "Epoch 00049: saving model to modified_checkpoints\\final_weights.49.hdf5\n",
      "804/804 [==============================] - 0s 584us/step - loss: 0.5308 - accuracy: 0.7418\n",
      "Epoch 50/100\n",
      "590/804 [=====================>........] - ETA: 0s - loss: 0.5304 - accuracy: 0.7425\n",
      "Epoch 00050: saving model to modified_checkpoints\\final_weights.50.hdf5\n",
      "804/804 [==============================] - 0s 602us/step - loss: 0.5313 - accuracy: 0.7426\n",
      "Epoch 51/100\n",
      "796/804 [============================>.] - ETA: 0s - loss: 0.5319 - accuracy: 0.7422\n",
      "Epoch 00051: saving model to modified_checkpoints\\final_weights.51.hdf5\n",
      "804/804 [==============================] - 0s 584us/step - loss: 0.5313 - accuracy: 0.7426\n",
      "Epoch 52/100\n",
      "804/804 [==============================] - 0s 576us/step - loss: 0.5309 - accuracy: 0.7423\n",
      "Epoch 53/100\n",
      "178/804 [=====>........................] - ETA: 0s - loss: 0.5360 - accuracy: 0.7354\n",
      "Epoch 00053: saving model to modified_checkpoints\\final_weights.53.hdf5\n",
      "804/804 [==============================] - 0s 619us/step - loss: 0.5303 - accuracy: 0.7435\n",
      "Epoch 54/100\n",
      "349/804 [============>.................] - ETA: 0s - loss: 0.5320 - accuracy: 0.7412\n",
      "Epoch 00054: saving model to modified_checkpoints\\final_weights.54.hdf5\n",
      "804/804 [==============================] - 0s 587us/step - loss: 0.5303 - accuracy: 0.7427\n",
      "Epoch 55/100\n",
      "536/804 [===================>..........] - ETA: 0s - loss: 0.5309 - accuracy: 0.7413\n",
      "Epoch 00055: saving model to modified_checkpoints\\final_weights.55.hdf5\n",
      "804/804 [==============================] - 0s 604us/step - loss: 0.5315 - accuracy: 0.7420\n",
      "Epoch 56/100\n",
      "771/804 [===========================>..] - ETA: 0s - loss: 0.5298 - accuracy: 0.7429\n",
      "Epoch 00056: saving model to modified_checkpoints\\final_weights.56.hdf5\n",
      "804/804 [==============================] - 0s 602us/step - loss: 0.5304 - accuracy: 0.7426\n",
      "Epoch 57/100\n",
      "804/804 [==============================] - 0s 583us/step - loss: 0.5315 - accuracy: 0.7431\n",
      "Epoch 58/100\n",
      " 87/804 [==>...........................] - ETA: 0s - loss: 0.5427 - accuracy: 0.7324\n",
      "Epoch 00058: saving model to modified_checkpoints\\final_weights.58.hdf5\n",
      "804/804 [==============================] - 0s 590us/step - loss: 0.5302 - accuracy: 0.7424\n",
      "Epoch 59/100\n",
      "333/804 [===========>..................] - ETA: 0s - loss: 0.5340 - accuracy: 0.7365\n",
      "Epoch 00059: saving model to modified_checkpoints\\final_weights.59.hdf5\n",
      "804/804 [==============================] - 1s 661us/step - loss: 0.5299 - accuracy: 0.7429\n",
      "Epoch 60/100\n",
      "479/804 [================>.............] - ETA: 0s - loss: 0.5306 - accuracy: 0.7440\n",
      "Epoch 00060: saving model to modified_checkpoints\\final_weights.60.hdf5\n",
      "804/804 [==============================] - 1s 623us/step - loss: 0.5303 - accuracy: 0.7425\n",
      "Epoch 61/100\n",
      "705/804 [=========================>....] - ETA: 0s - loss: 0.5312 - accuracy: 0.7443\n",
      "Epoch 00061: saving model to modified_checkpoints\\final_weights.61.hdf5\n",
      "804/804 [==============================] - 0s 588us/step - loss: 0.5336 - accuracy: 0.7425\n",
      "Epoch 62/100\n",
      "804/804 [==============================] - 0s 574us/step - loss: 0.5304 - accuracy: 0.7428\n",
      "Epoch 63/100\n",
      " 92/804 [==>...........................] - ETA: 0s - loss: 0.5226 - accuracy: 0.7398\n",
      "Epoch 00063: saving model to modified_checkpoints\\final_weights.63.hdf5\n",
      "804/804 [==============================] - 0s 587us/step - loss: 0.5299 - accuracy: 0.7433\n",
      "Epoch 64/100\n",
      "308/804 [==========>...................] - ETA: 0s - loss: 0.5294 - accuracy: 0.7426\n",
      "Epoch 00064: saving model to modified_checkpoints\\final_weights.64.hdf5\n",
      "804/804 [==============================] - 0s 615us/step - loss: 0.5304 - accuracy: 0.7422\n",
      "Epoch 65/100\n",
      "533/804 [==================>...........] - ETA: 0s - loss: 0.5282 - accuracy: 0.7433\n",
      "Epoch 00065: saving model to modified_checkpoints\\final_weights.65.hdf5\n",
      "804/804 [==============================] - 0s 588us/step - loss: 0.5304 - accuracy: 0.7423\n",
      "Epoch 66/100\n",
      "682/804 [========================>.....] - ETA: 0s - loss: 0.5293 - accuracy: 0.7444\n",
      "Epoch 00066: saving model to modified_checkpoints\\final_weights.66.hdf5\n",
      "804/804 [==============================] - 0s 613us/step - loss: 0.5302 - accuracy: 0.7430\n",
      "Epoch 67/100\n",
      "804/804 [==============================] - 1s 686us/step - loss: 0.5299 - accuracy: 0.7431\n",
      "Epoch 68/100\n",
      " 86/804 [==>...........................] - ETA: 0s - loss: 0.5314 - accuracy: 0.7376\n",
      "Epoch 00068: saving model to modified_checkpoints\\final_weights.68.hdf5\n",
      "804/804 [==============================] - 1s 624us/step - loss: 0.5299 - accuracy: 0.7428\n",
      "Epoch 69/100\n",
      "262/804 [========>.....................] - ETA: 0s - loss: 0.5320 - accuracy: 0.7448\n",
      "Epoch 00069: saving model to modified_checkpoints\\final_weights.69.hdf5\n",
      "804/804 [==============================] - 0s 592us/step - loss: 0.5300 - accuracy: 0.7427\n",
      "Epoch 70/100\n",
      "443/804 [===============>..............] - ETA: 0s - loss: 0.5326 - accuracy: 0.7423\n",
      "Epoch 00070: saving model to modified_checkpoints\\final_weights.70.hdf5\n",
      "804/804 [==============================] - 0s 584us/step - loss: 0.5302 - accuracy: 0.7428\n",
      "Epoch 71/100\n",
      "645/804 [=======================>......] - ETA: 0s - loss: 0.5289 - accuracy: 0.7431\n",
      "Epoch 00071: saving model to modified_checkpoints\\final_weights.71.hdf5\n",
      "804/804 [==============================] - 1s 630us/step - loss: 0.5320 - accuracy: 0.7421\n",
      "Epoch 72/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "804/804 [==============================] - 0s 618us/step - loss: 0.5299 - accuracy: 0.7428\n",
      "Epoch 73/100\n",
      " 89/804 [==>...........................] - ETA: 0s - loss: 0.5348 - accuracy: 0.7412\n",
      "Epoch 00073: saving model to modified_checkpoints\\final_weights.73.hdf5\n",
      "804/804 [==============================] - 0s 589us/step - loss: 0.5300 - accuracy: 0.7429\n",
      "Epoch 74/100\n",
      "265/804 [========>.....................] - ETA: 0s - loss: 0.5278 - accuracy: 0.7439\n",
      "Epoch 00074: saving model to modified_checkpoints\\final_weights.74.hdf5\n",
      "804/804 [==============================] - 0s 587us/step - loss: 0.5297 - accuracy: 0.7430\n",
      "Epoch 75/100\n",
      "477/804 [================>.............] - ETA: 0s - loss: 0.5326 - accuracy: 0.7404\n",
      "Epoch 00075: saving model to modified_checkpoints\\final_weights.75.hdf5\n",
      "804/804 [==============================] - 1s 636us/step - loss: 0.5297 - accuracy: 0.7427\n",
      "Epoch 76/100\n",
      "693/804 [========================>.....] - ETA: 0s - loss: 0.5299 - accuracy: 0.7424\n",
      "Epoch 00076: saving model to modified_checkpoints\\final_weights.76.hdf5\n",
      "804/804 [==============================] - 0s 595us/step - loss: 0.5296 - accuracy: 0.7428\n",
      "Epoch 77/100\n",
      "804/804 [==============================] - 0s 593us/step - loss: 0.5323 - accuracy: 0.7428\n",
      "Epoch 78/100\n",
      " 87/804 [==>...........................] - ETA: 0s - loss: 0.5265 - accuracy: 0.7478\n",
      "Epoch 00078: saving model to modified_checkpoints\\final_weights.78.hdf5\n",
      "804/804 [==============================] - 0s 597us/step - loss: 0.5332 - accuracy: 0.7432\n",
      "Epoch 79/100\n",
      "263/804 [========>.....................] - ETA: 0s - loss: 0.5342 - accuracy: 0.7381\n",
      "Epoch 00079: saving model to modified_checkpoints\\final_weights.79.hdf5\n",
      "804/804 [==============================] - 0s 621us/step - loss: 0.5299 - accuracy: 0.7432\n",
      "Epoch 80/100\n",
      "433/804 [===============>..............] - ETA: 0s - loss: 0.5347 - accuracy: 0.7387\n",
      "Epoch 00080: saving model to modified_checkpoints\\final_weights.80.hdf5\n",
      "804/804 [==============================] - 0s 593us/step - loss: 0.5295 - accuracy: 0.7430\n",
      "Epoch 81/100\n",
      "676/804 [========================>.....] - ETA: 0s - loss: 0.5288 - accuracy: 0.7440\n",
      "Epoch 00081: saving model to modified_checkpoints\\final_weights.81.hdf5\n",
      "804/804 [==============================] - 0s 612us/step - loss: 0.5301 - accuracy: 0.7428\n",
      "Epoch 82/100\n",
      "804/804 [==============================] - 0s 595us/step - loss: 0.5296 - accuracy: 0.7429\n",
      "Epoch 83/100\n",
      "  1/804 [..............................] - ETA: 0s - loss: 0.5727 - accuracy: 0.6562\n",
      "Epoch 00083: saving model to modified_checkpoints\\final_weights.83.hdf5\n",
      "804/804 [==============================] - 1s 634us/step - loss: 0.5308 - accuracy: 0.7422\n",
      "Epoch 84/100\n",
      "259/804 [========>.....................] - ETA: 0s - loss: 0.5208 - accuracy: 0.7531\n",
      "Epoch 00084: saving model to modified_checkpoints\\final_weights.84.hdf5\n",
      "804/804 [==============================] - 0s 593us/step - loss: 0.5300 - accuracy: 0.7430\n",
      "Epoch 85/100\n",
      "439/804 [===============>..............] - ETA: 0s - loss: 0.5289 - accuracy: 0.7432\n",
      "Epoch 00085: saving model to modified_checkpoints\\final_weights.85.hdf5\n",
      "804/804 [==============================] - 0s 588us/step - loss: 0.5296 - accuracy: 0.7431\n",
      "Epoch 86/100\n",
      "619/804 [======================>.......] - ETA: 0s - loss: 0.5307 - accuracy: 0.7432\n",
      "Epoch 00086: saving model to modified_checkpoints\\final_weights.86.hdf5\n",
      "804/804 [==============================] - 0s 586us/step - loss: 0.5305 - accuracy: 0.7434\n",
      "Epoch 87/100\n",
      "804/804 [==============================] - 1s 630us/step - loss: 0.5298 - accuracy: 0.7428\n",
      "Epoch 88/100\n",
      "  1/804 [..............................] - ETA: 0s - loss: 0.6581 - accuracy: 0.6875\n",
      "Epoch 00088: saving model to modified_checkpoints\\final_weights.88.hdf5\n",
      "804/804 [==============================] - 0s 603us/step - loss: 0.5297 - accuracy: 0.7431\n",
      "Epoch 89/100\n",
      "172/804 [=====>........................] - ETA: 0s - loss: 0.5330 - accuracy: 0.7351\n",
      "Epoch 00089: saving model to modified_checkpoints\\final_weights.89.hdf5\n",
      "804/804 [==============================] - 0s 600us/step - loss: 0.5309 - accuracy: 0.7432\n",
      "Epoch 90/100\n",
      "431/804 [===============>..............] - ETA: 0s - loss: 0.5311 - accuracy: 0.7423\n",
      "Epoch 00090: saving model to modified_checkpoints\\final_weights.90.hdf5\n",
      "804/804 [==============================] - 0s 598us/step - loss: 0.5350 - accuracy: 0.7422\n",
      "Epoch 91/100\n",
      "600/804 [=====================>........] - ETA: 0s - loss: 0.5299 - accuracy: 0.7433\n",
      "Epoch 00091: saving model to modified_checkpoints\\final_weights.91.hdf5\n",
      "804/804 [==============================] - 1s 672us/step - loss: 0.5311 - accuracy: 0.7429\n",
      "Epoch 92/100\n",
      "804/804 [==============================] - 0s 612us/step - loss: 0.5295 - accuracy: 0.7429\n",
      "Epoch 93/100\n",
      "  1/804 [..............................] - ETA: 0s - loss: 0.5911 - accuracy: 0.7188\n",
      "Epoch 00093: saving model to modified_checkpoints\\final_weights.93.hdf5\n",
      "804/804 [==============================] - 0s 585us/step - loss: 0.5303 - accuracy: 0.7432\n",
      "Epoch 94/100\n",
      "173/804 [=====>........................] - ETA: 0s - loss: 0.5256 - accuracy: 0.7437\n",
      "Epoch 00094: saving model to modified_checkpoints\\final_weights.94.hdf5\n",
      "804/804 [==============================] - 0s 598us/step - loss: 0.5295 - accuracy: 0.7433\n",
      "Epoch 95/100\n",
      "395/804 [=============>................] - ETA: 0s - loss: 0.5299 - accuracy: 0.7432\n",
      "Epoch 00095: saving model to modified_checkpoints\\final_weights.95.hdf5\n",
      "804/804 [==============================] - 0s 619us/step - loss: 0.5295 - accuracy: 0.7424\n",
      "Epoch 96/100\n",
      "532/804 [==================>...........] - ETA: 0s - loss: 0.5299 - accuracy: 0.7440\n",
      "Epoch 00096: saving model to modified_checkpoints\\final_weights.96.hdf5\n",
      "804/804 [==============================] - 0s 588us/step - loss: 0.5298 - accuracy: 0.7431\n",
      "Epoch 97/100\n",
      "804/804 [==============================] - 0s 585us/step - loss: 0.5294 - accuracy: 0.7430\n",
      "Epoch 98/100\n",
      "  1/804 [..............................] - ETA: 0s - loss: 0.6386 - accuracy: 0.6250\n",
      "Epoch 00098: saving model to modified_checkpoints\\final_weights.98.hdf5\n",
      "804/804 [==============================] - 0s 597us/step - loss: 0.5301 - accuracy: 0.7429\n",
      "Epoch 99/100\n",
      "205/804 [======>.......................] - ETA: 0s - loss: 0.5292 - accuracy: 0.7483\n",
      "Epoch 00099: saving model to modified_checkpoints\\final_weights.99.hdf5\n",
      "804/804 [==============================] - 1s 629us/step - loss: 0.5320 - accuracy: 0.7428\n",
      "Epoch 100/100\n",
      "351/804 [============>.................] - ETA: 0s - loss: 0.5378 - accuracy: 0.7378\n",
      "Epoch 00100: saving model to modified_checkpoints\\final_weights.100.hdf5\n",
      "804/804 [==============================] - 0s 590us/step - loss: 0.5302 - accuracy: 0.7430\n"
     ]
    }
   ],
   "source": [
    "fit_model_final = nn.fit(x_train_scaled, y_train, epochs=100,callbacks=[cp_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 - 0s - loss: 0.6047 - accuracy: 0.7254\n",
      "Attempt 4\n",
      "Loss: 0.6047123670578003, Accuracy: 0.7253644466400146\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "model_loss, model_accuracy = nn.evaluate(x_test_scaled,y_test,verbose=2)\n",
    "print(\"Attempt 4\")\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save and export your results to an HDF5 file, and name it \"AlphabetSoupCharity.h5\"\n",
    "# Export our model to HDF5 file\n",
    "nn.save(\"AlphabetSoupCharity_final.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PYthonData",
   "language": "python",
   "name": "pythondata"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
